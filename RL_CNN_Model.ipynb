{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\carlo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "# libraries\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten, Dropout\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from sklearn.metrics import (confusion_matrix, accuracy_score, classification_report,ConfusionMatrixDisplay)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import collections\n",
    "\n",
    "import gym\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "import os\n",
    "import scipy.io as sio\n",
    "from scipy.fft import fft\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DDQN model with CNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset, returns train and test X and y elements\n",
    "def load_dataset():\n",
    "\n",
    "\t# load all data\n",
    "\twith open('data/processed/trainX.npy', 'rb') as f:\n",
    "\t\ttrainX = np.load(f)\n",
    "\twith open('data/processed/trainy.npy', 'rb') as f:\n",
    "\t\ttrainy = np.load(f)\n",
    "\twith open('data/processed/testX.npy', 'rb') as f:\n",
    "\t\ttestX = np.load(f)\n",
    "\twith open('data/processed/testy.npy', 'rb') as f:\n",
    "\t\ttesty = np.load(f)\n",
    "\t\n",
    "\tprint(trainX.shape, trainy.shape, testX.shape, testy.shape)\n",
    "\t\n",
    "\treturn trainX, trainy, testX, testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "def get_model(trainX, trainy, learning_rate):\n",
    "    n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=3, kernel_size=5, activation='relu',input_shape=(n_timesteps,n_features)))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Conv1D(filters=12, kernel_size=2, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Experience = collections.namedtuple('Experience', \n",
    "           field_names=['state', 'action', 'reward', \n",
    "           'new_state', 'done'])\n",
    "           \n",
    "class ExperiencePool:\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = collections.deque(maxlen=capacity)\n",
    "        self.pool_counter= 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "    def append(self, experience):\n",
    "        self.buffer.append(experience)\n",
    "        self.pool_counter += 1\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        indices = np.random.choice(len(self.buffer), batch_size, replace=False)\n",
    "        states, actions, rewards, next_states, dones = zip(*[self.buffer[idx] for idx in indices])\n",
    "        return np.array(states), np.array(actions), \\\n",
    "                np.array(rewards,dtype=np.float32), \\\n",
    "                np.array(next_states), \\\n",
    "                np.array(dones, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDQNAgent(object):\n",
    "    def __init__(self, learning_rate, discount_factor, action_space,\n",
    "                 trainX, trainy, batch_size,\n",
    "                 epsilon_decay, epsilon_min, epsilon_0,\n",
    "                 mem_size, replace_target):\n",
    "        \n",
    "        self.action_space = action_space\n",
    "        self.n_actions = 3\n",
    "        self.gamma = discount_factor\n",
    "\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.epsilon_0 = epsilon_0\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.epsilon = self.epsilon_min + (self.epsilon_0-self.epsilon_min)*np.exp(-self.epsilon_decay)\n",
    "        self.reward_count = 0\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.replace_target = replace_target\n",
    "        self.pool = ExperiencePool(mem_size)\n",
    "        \n",
    "        self.q_policy = get_model(trainX, trainy, learning_rate)\n",
    "        self.q_target = get_model(trainX, trainy, learning_rate)\n",
    "        self.update_network_parameters()\n",
    "\n",
    "    def update_epsilon(self):\n",
    "        self.epsilon = self.epsilon_min + (self.epsilon_0-self.epsilon_min)*np.exp(-self.epsilon_decay*self.episode_count)\n",
    "\n",
    "    def reset_pool(self, mem_size):\n",
    "        self.pool = ExperiencePool(mem_size)\n",
    "\n",
    "    def set_episode_count(self, episode_count):\n",
    "        self.episode_count = episode_count\n",
    "\n",
    "    def add_experience(self, experience): #state, action, reward, new_state, done\n",
    "        self.pool.append(experience) #state, action, reward, new_state, done\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        state = state[np.newaxis, :]\n",
    "        rand = np.random.random()\n",
    "        if rand < self.epsilon:\n",
    "            action = np.random.choice(self.action_space)\n",
    "        else:\n",
    "            actions = self.q_policy.predict(state,verbose=0)\n",
    "            action = np.argmax(actions)\n",
    "\n",
    "        return action\n",
    "\n",
    "    def learn(self):\n",
    "        if self.pool.pool_counter >= self.batch_size:\n",
    "            states, actions, rewards, new_states, dones = self.pool.sample(self.batch_size)\n",
    "\n",
    "            q_next_target = self.q_target.predict(new_states, verbose=0)\n",
    "            q_policy_next = self.q_policy.predict(new_states, verbose=0)\n",
    "            q_policy_pred = self.q_policy.predict(states, verbose=0)\n",
    "\n",
    "            max_actions = np.argmax(q_policy_next, axis=1)\n",
    "\n",
    "            y_j = q_policy_pred\n",
    "\n",
    "            batch_index = np.arange(self.batch_size, dtype=np.int32)\n",
    "            \n",
    "            y_j[batch_index, actions] = rewards + \\\n",
    "                    self.gamma*q_next_target[batch_index, max_actions.astype(int)]*dones\n",
    "\n",
    "            history = self.q_policy.fit(states, y_j, verbose=2)\n",
    "            \n",
    "            if self.episode_count % self.replace_target == 0:\n",
    "                self.update_network_parameters()\n",
    "\n",
    "            return history.history['accuracy'], history.history['loss']\n",
    "        return 0,0\n",
    "\n",
    "    def update_network_parameters(self):\n",
    "        self.q_target.set_weights(self.q_policy.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PowerPlantEnv(gym.Env):\n",
    "    def __init__(self, dataset):\n",
    "        super().__init__()\n",
    "        self.action_space = gym.spaces.Discrete(3) # 3 classes\n",
    "        self.x, self.y = dataset\n",
    "\n",
    "    def step(self, action):\n",
    "        if action == self.expected_action:\n",
    "            reward = 1\n",
    "        else:\n",
    "            reward = -1\n",
    "            \n",
    "        obs = self._next_obs()\n",
    "\n",
    "        return obs, reward, False, {}\n",
    "\n",
    "    def _next_obs(self):\n",
    "        next_obs_idx = random.randint(0, len(self.x) - 1)\n",
    "        self.expected_action = np.argmax(self.y[next_obs_idx])\n",
    "        obs = self.x[next_obs_idx]\n",
    "\n",
    "        return obs\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49209, 512, 2) (49209, 3) (10545, 512, 2) (10545, 3)\n",
      "\n",
      ">> Episode:  1 / 800\n",
      "2/2 - 1s - loss: 0.4627 - accuracy: 0.4219 - 647ms/epoch - 323ms/step\n",
      "Cummulative reward:  -28\n",
      "\n",
      ">> Episode:  2 / 800\n",
      "2/2 - 0s - loss: 0.4911 - accuracy: 0.3906 - 18ms/epoch - 9ms/step\n",
      "Cummulative reward:  -16\n",
      "\n",
      ">> Episode:  3 / 800\n",
      "2/2 - 0s - loss: 0.4951 - accuracy: 0.3281 - 18ms/epoch - 9ms/step\n",
      "Cummulative reward:  -20\n",
      "\n",
      ">> Episode:  4 / 800\n",
      "2/2 - 0s - loss: 0.4822 - accuracy: 0.4375 - 18ms/epoch - 9ms/step\n",
      "Cummulative reward:  -24\n",
      "\n",
      ">> Episode:  5 / 800\n",
      "2/2 - 0s - loss: 0.5050 - accuracy: 0.3125 - 18ms/epoch - 9ms/step\n",
      "Cummulative reward:  -26\n",
      "\n",
      ">> Episode:  6 / 800\n",
      "2/2 - 0s - loss: 0.4249 - accuracy: 0.3906 - 18ms/epoch - 9ms/step\n",
      "Cummulative reward:  -10\n",
      "\n",
      ">> Episode:  7 / 800\n",
      "2/2 - 0s - loss: 0.4024 - accuracy: 0.3594 - 19ms/epoch - 10ms/step\n",
      "Cummulative reward:  -8\n",
      "\n",
      ">> Episode:  8 / 800\n",
      "2/2 - 0s - loss: 0.4558 - accuracy: 0.4531 - 19ms/epoch - 10ms/step\n",
      "Cummulative reward:  -24\n",
      "\n",
      ">> Episode:  9 / 800\n",
      "2/2 - 0s - loss: 0.4773 - accuracy: 0.2969 - 18ms/epoch - 9ms/step\n",
      "Cummulative reward:  -26\n",
      "\n",
      ">> Episode:  10 / 800\n",
      "2/2 - 0s - loss: 0.4680 - accuracy: 0.3438 - 19ms/epoch - 9ms/step\n",
      "Cummulative reward:  -24\n",
      "\n",
      ">> Episode:  11 / 800\n",
      "2/2 - 0s - loss: 0.4240 - accuracy: 0.4375 - 20ms/epoch - 10ms/step\n",
      "Cummulative reward:  -14\n",
      "\n",
      ">> Episode:  12 / 800\n",
      "2/2 - 0s - loss: 0.3992 - accuracy: 0.4844 - 19ms/epoch - 9ms/step\n",
      "Cummulative reward:  -8\n",
      "\n",
      ">> Episode:  13 / 800\n",
      "2/2 - 0s - loss: 0.3614 - accuracy: 0.5469 - 19ms/epoch - 9ms/step\n",
      "Cummulative reward:  2\n",
      "\n",
      ">> Episode:  14 / 800\n",
      "2/2 - 0s - loss: 0.4026 - accuracy: 0.4375 - 18ms/epoch - 9ms/step\n",
      "Cummulative reward:  -8\n",
      "\n",
      ">> Episode:  15 / 800\n",
      "2/2 - 0s - loss: 0.4334 - accuracy: 0.3750 - 18ms/epoch - 9ms/step\n",
      "Cummulative reward:  -16\n",
      "\n",
      ">> Episode:  16 / 800\n",
      "2/2 - 0s - loss: 0.3848 - accuracy: 0.5156 - 18ms/epoch - 9ms/step\n",
      "Cummulative reward:  -4\n",
      "\n",
      ">> Episode:  17 / 800\n",
      "2/2 - 0s - loss: 0.4305 - accuracy: 0.4062 - 19ms/epoch - 10ms/step\n",
      "Cummulative reward:  -16\n",
      "\n",
      ">> Episode:  18 / 800\n",
      "2/2 - 0s - loss: 0.3362 - accuracy: 0.5781 - 18ms/epoch - 9ms/step\n",
      "Cummulative reward:  10\n",
      "\n",
      ">> Episode:  19 / 800\n",
      "2/2 - 0s - loss: 0.3787 - accuracy: 0.5156 - 19ms/epoch - 10ms/step\n",
      "Cummulative reward:  -2\n",
      "\n",
      ">> Episode:  20 / 800\n",
      "2/2 - 0s - loss: 0.4329 - accuracy: 0.4062 - 18ms/epoch - 9ms/step\n",
      "Cummulative reward:  -18\n",
      "\n",
      ">> Episode:  21 / 800\n",
      "2/2 - 0s - loss: 0.3702 - accuracy: 0.5312 - 18ms/epoch - 9ms/step\n",
      "Cummulative reward:  0\n",
      "\n",
      ">> Episode:  22 / 800\n",
      "2/2 - 0s - loss: 0.3858 - accuracy: 0.4844 - 18ms/epoch - 9ms/step\n",
      "Cummulative reward:  -4\n",
      "\n",
      ">> Episode:  23 / 800\n",
      "2/2 - 0s - loss: 0.3544 - accuracy: 0.5625 - 20ms/epoch - 10ms/step\n",
      "Cummulative reward:  4\n",
      "\n",
      ">> Episode:  24 / 800\n",
      "2/2 - 0s - loss: 0.4127 - accuracy: 0.4531 - 17ms/epoch - 9ms/step\n",
      "Cummulative reward:  -12\n",
      "\n",
      ">> Episode:  25 / 800\n",
      "2/2 - 0s - loss: 0.3178 - accuracy: 0.6250 - 17ms/epoch - 8ms/step\n",
      "Cummulative reward:  14\n",
      "\n",
      ">> Episode:  26 / 800\n",
      "2/2 - 0s - loss: 0.3665 - accuracy: 0.5469 - 18ms/epoch - 9ms/step\n",
      "Cummulative reward:  0\n",
      "\n",
      ">> Episode:  27 / 800\n",
      "2/2 - 0s - loss: 0.3683 - accuracy: 0.4688 - 21ms/epoch - 10ms/step\n",
      "Cummulative reward:  0\n",
      "\n",
      ">> Episode:  28 / 800\n",
      "2/2 - 0s - loss: 0.4138 - accuracy: 0.4375 - 19ms/epoch - 9ms/step\n",
      "Cummulative reward:  -12\n",
      "\n",
      ">> Episode:  29 / 800\n",
      "2/2 - 0s - loss: 0.3628 - accuracy: 0.5625 - 17ms/epoch - 9ms/step\n",
      "Cummulative reward:  2\n",
      "\n",
      ">> Episode:  30 / 800\n",
      "2/2 - 0s - loss: 0.4160 - accuracy: 0.3750 - 20ms/epoch - 10ms/step\n",
      "Cummulative reward:  -12\n",
      "\n",
      ">> Episode:  31 / 800\n",
      "2/2 - 0s - loss: 0.3464 - accuracy: 0.5312 - 22ms/epoch - 11ms/step\n",
      "Cummulative reward:  6\n",
      "\n",
      ">> Episode:  32 / 800\n",
      "2/2 - 0s - loss: 0.4007 - accuracy: 0.4375 - 22ms/epoch - 11ms/step\n",
      "Cummulative reward:  -8\n",
      "\n",
      ">> Episode:  33 / 800\n",
      "2/2 - 0s - loss: 0.3539 - accuracy: 0.5469 - 22ms/epoch - 11ms/step\n",
      "Cummulative reward:  4\n",
      "\n",
      ">> Episode:  34 / 800\n",
      "2/2 - 0s - loss: 0.3419 - accuracy: 0.5625 - 22ms/epoch - 11ms/step\n",
      "Cummulative reward:  8\n",
      "\n",
      ">> Episode:  35 / 800\n",
      "2/2 - 0s - loss: 0.3772 - accuracy: 0.4844 - 24ms/epoch - 12ms/step\n",
      "Cummulative reward:  -2\n",
      "\n",
      ">> Episode:  36 / 800\n",
      "2/2 - 0s - loss: 0.3818 - accuracy: 0.4844 - 20ms/epoch - 10ms/step\n",
      "Cummulative reward:  -4\n",
      "\n",
      ">> Episode:  37 / 800\n",
      "2/2 - 0s - loss: 0.3174 - accuracy: 0.6250 - 20ms/epoch - 10ms/step\n",
      "Cummulative reward:  14\n",
      "\n",
      ">> Episode:  38 / 800\n",
      "2/2 - 0s - loss: 0.3522 - accuracy: 0.5938 - 21ms/epoch - 11ms/step\n",
      "Cummulative reward:  4\n",
      "\n",
      ">> Episode:  39 / 800\n",
      "2/2 - 0s - loss: 0.3467 - accuracy: 0.5469 - 20ms/epoch - 10ms/step\n",
      "Cummulative reward:  6\n",
      "\n",
      ">> Episode:  40 / 800\n",
      "2/2 - 0s - loss: 0.3596 - accuracy: 0.5156 - 19ms/epoch - 9ms/step\n",
      "Cummulative reward:  2\n",
      "\n",
      ">> Episode:  41 / 800\n",
      "2/2 - 0s - loss: 0.3856 - accuracy: 0.4688 - 20ms/epoch - 10ms/step\n",
      "Cummulative reward:  -6\n",
      "\n",
      ">> Episode:  42 / 800\n",
      "2/2 - 0s - loss: 0.3766 - accuracy: 0.4844 - 21ms/epoch - 11ms/step\n",
      "Cummulative reward:  -2\n",
      "\n",
      ">> Episode:  43 / 800\n",
      "2/2 - 0s - loss: 0.3690 - accuracy: 0.5000 - 21ms/epoch - 10ms/step\n",
      "Cummulative reward:  0\n",
      "\n",
      ">> Episode:  44 / 800\n",
      "2/2 - 0s - loss: 0.3151 - accuracy: 0.6094 - 20ms/epoch - 10ms/step\n",
      "Cummulative reward:  14\n",
      "\n",
      ">> Episode:  45 / 800\n",
      "2/2 - 0s - loss: 0.3264 - accuracy: 0.5625 - 21ms/epoch - 10ms/step\n",
      "Cummulative reward:  10\n",
      "\n",
      ">> Episode:  46 / 800\n",
      "2/2 - 0s - loss: 0.3854 - accuracy: 0.4688 - 19ms/epoch - 10ms/step\n",
      "Cummulative reward:  -4\n",
      "\n",
      ">> Episode:  47 / 800\n",
      "2/2 - 0s - loss: 0.3390 - accuracy: 0.5781 - 21ms/epoch - 10ms/step\n",
      "Cummulative reward:  8\n",
      "\n",
      ">> Episode:  48 / 800\n",
      "2/2 - 0s - loss: 0.3650 - accuracy: 0.5000 - 21ms/epoch - 11ms/step\n",
      "Cummulative reward:  0\n",
      "\n",
      ">> Episode:  49 / 800\n",
      "2/2 - 0s - loss: 0.3621 - accuracy: 0.4844 - 23ms/epoch - 11ms/step\n",
      "Cummulative reward:  2\n",
      "\n",
      ">> Episode:  50 / 800\n",
      "2/2 - 0s - loss: 0.3260 - accuracy: 0.5938 - 32ms/epoch - 16ms/step\n",
      "Cummulative reward:  10\n",
      "\n",
      ">> Episode:  51 / 800\n",
      "2/2 - 0s - loss: 0.3088 - accuracy: 0.5938 - 33ms/epoch - 16ms/step\n",
      "Cummulative reward:  14\n",
      "\n",
      ">> Episode:  52 / 800\n",
      "2/2 - 0s - loss: 0.2920 - accuracy: 0.6250 - 21ms/epoch - 10ms/step\n",
      "Cummulative reward:  18\n",
      "\n",
      ">> Episode:  53 / 800\n",
      "2/2 - 0s - loss: 0.2870 - accuracy: 0.6406 - 21ms/epoch - 11ms/step\n",
      "Cummulative reward:  22\n",
      "\n",
      ">> Episode:  54 / 800\n",
      "2/2 - 0s - loss: 0.3087 - accuracy: 0.6250 - 21ms/epoch - 11ms/step\n",
      "Cummulative reward:  14\n",
      "\n",
      ">> Episode:  55 / 800\n",
      "2/2 - 0s - loss: 0.3468 - accuracy: 0.5625 - 25ms/epoch - 13ms/step\n",
      "Cummulative reward:  8\n",
      "\n",
      ">> Episode:  56 / 800\n",
      "2/2 - 0s - loss: 0.3270 - accuracy: 0.5938 - 23ms/epoch - 12ms/step\n",
      "Cummulative reward:  10\n",
      "\n",
      ">> Episode:  57 / 800\n",
      "2/2 - 0s - loss: 0.3918 - accuracy: 0.4844 - 22ms/epoch - 11ms/step\n",
      "Cummulative reward:  -6\n",
      "\n",
      ">> Episode:  58 / 800\n",
      "2/2 - 0s - loss: 0.3391 - accuracy: 0.5938 - 23ms/epoch - 11ms/step\n",
      "Cummulative reward:  8\n",
      "\n",
      ">> Episode:  59 / 800\n",
      "2/2 - 0s - loss: 0.3785 - accuracy: 0.5156 - 20ms/epoch - 10ms/step\n",
      "Cummulative reward:  -2\n",
      "\n",
      ">> Episode:  60 / 800\n",
      "2/2 - 0s - loss: 0.3247 - accuracy: 0.5938 - 24ms/epoch - 12ms/step\n",
      "Cummulative reward:  10\n",
      "\n",
      ">> Episode:  61 / 800\n",
      "2/2 - 0s - loss: 0.3012 - accuracy: 0.6875 - 22ms/epoch - 11ms/step\n",
      "Cummulative reward:  18\n",
      "\n",
      ">> Episode:  62 / 800\n",
      "2/2 - 0s - loss: 0.3125 - accuracy: 0.6094 - 21ms/epoch - 10ms/step\n",
      "Cummulative reward:  14\n",
      "\n",
      ">> Episode:  63 / 800\n",
      "2/2 - 0s - loss: 0.3712 - accuracy: 0.5625 - 21ms/epoch - 10ms/step\n",
      "Cummulative reward:  -2\n",
      "\n",
      ">> Episode:  64 / 800\n",
      "2/2 - 0s - loss: 0.2624 - accuracy: 0.7031 - 20ms/epoch - 10ms/step\n",
      "Cummulative reward:  28\n",
      "\n",
      ">> Episode:  65 / 800\n",
      "2/2 - 0s - loss: 0.3448 - accuracy: 0.5469 - 25ms/epoch - 12ms/step\n",
      "Cummulative reward:  8\n",
      "\n",
      ">> Episode:  66 / 800\n",
      "2/2 - 0s - loss: 0.3114 - accuracy: 0.6250 - 20ms/epoch - 10ms/step\n",
      "Cummulative reward:  14\n",
      "\n",
      ">> Episode:  67 / 800\n",
      "2/2 - 0s - loss: 0.2865 - accuracy: 0.6562 - 20ms/epoch - 10ms/step\n",
      "Cummulative reward:  18\n",
      "\n",
      ">> Episode:  68 / 800\n",
      "2/2 - 0s - loss: 0.3319 - accuracy: 0.5625 - 21ms/epoch - 11ms/step\n",
      "Cummulative reward:  8\n",
      "\n",
      ">> Episode:  69 / 800\n",
      "2/2 - 0s - loss: 0.3499 - accuracy: 0.5156 - 23ms/epoch - 11ms/step\n",
      "Cummulative reward:  2\n",
      "\n",
      ">> Episode:  70 / 800\n",
      "2/2 - 0s - loss: 0.3608 - accuracy: 0.5000 - 23ms/epoch - 11ms/step\n",
      "Cummulative reward:  2\n",
      "\n",
      ">> Episode:  71 / 800\n",
      "2/2 - 0s - loss: 0.3728 - accuracy: 0.5156 - 25ms/epoch - 12ms/step\n",
      "Cummulative reward:  -2\n",
      "\n",
      ">> Episode:  72 / 800\n",
      "2/2 - 0s - loss: 0.3411 - accuracy: 0.5469 - 21ms/epoch - 10ms/step\n",
      "Cummulative reward:  6\n",
      "\n",
      ">> Episode:  73 / 800\n",
      "2/2 - 0s - loss: 0.3210 - accuracy: 0.6406 - 21ms/epoch - 11ms/step\n",
      "Cummulative reward:  14\n",
      "\n",
      ">> Episode:  74 / 800\n",
      "2/2 - 0s - loss: 0.3472 - accuracy: 0.5156 - 21ms/epoch - 11ms/step\n",
      "Cummulative reward:  6\n",
      "\n",
      ">> Episode:  75 / 800\n",
      "2/2 - 0s - loss: 0.2818 - accuracy: 0.6719 - 21ms/epoch - 11ms/step\n",
      "Cummulative reward:  22\n",
      "\n",
      ">> Episode:  76 / 800\n",
      "2/2 - 0s - loss: 0.3682 - accuracy: 0.5000 - 21ms/epoch - 10ms/step\n",
      "Cummulative reward:  0\n",
      "\n",
      ">> Episode:  77 / 800\n",
      "2/2 - 0s - loss: 0.3615 - accuracy: 0.5000 - 23ms/epoch - 11ms/step\n",
      "Cummulative reward:  0\n",
      "\n",
      ">> Episode:  78 / 800\n",
      "2/2 - 0s - loss: 0.3453 - accuracy: 0.5625 - 23ms/epoch - 11ms/step\n",
      "Cummulative reward:  4\n",
      "\n",
      ">> Episode:  79 / 800\n",
      "2/2 - 0s - loss: 0.2817 - accuracy: 0.6562 - 23ms/epoch - 12ms/step\n",
      "Cummulative reward:  20\n",
      "\n",
      ">> Episode:  80 / 800\n",
      "2/2 - 0s - loss: 0.3481 - accuracy: 0.5625 - 32ms/epoch - 16ms/step\n",
      "Cummulative reward:  6\n",
      "\n",
      ">> Episode:  81 / 800\n",
      "2/2 - 0s - loss: 0.3027 - accuracy: 0.6094 - 23ms/epoch - 12ms/step\n",
      "Cummulative reward:  16\n",
      "\n",
      ">> Episode:  82 / 800\n",
      "2/2 - 0s - loss: 0.3588 - accuracy: 0.5781 - 24ms/epoch - 12ms/step\n",
      "Cummulative reward:  2\n",
      "\n",
      ">> Episode:  83 / 800\n",
      "2/2 - 0s - loss: 0.3176 - accuracy: 0.6094 - 26ms/epoch - 13ms/step\n",
      "Cummulative reward:  14\n",
      "\n",
      ">> Episode:  84 / 800\n",
      "2/2 - 0s - loss: 0.2937 - accuracy: 0.6719 - 22ms/epoch - 11ms/step\n",
      "Cummulative reward:  18\n",
      "\n",
      ">> Episode:  85 / 800\n",
      "2/2 - 0s - loss: 0.3116 - accuracy: 0.6094 - 22ms/epoch - 11ms/step\n",
      "Cummulative reward:  14\n",
      "\n",
      ">> Episode:  86 / 800\n",
      "2/2 - 0s - loss: 0.2986 - accuracy: 0.6094 - 29ms/epoch - 14ms/step\n",
      "Cummulative reward:  16\n",
      "\n",
      ">> Episode:  87 / 800\n",
      "2/2 - 0s - loss: 0.3395 - accuracy: 0.5625 - 29ms/epoch - 14ms/step\n",
      "Cummulative reward:  10\n",
      "\n",
      ">> Episode:  88 / 800\n",
      "2/2 - 0s - loss: 0.3398 - accuracy: 0.5312 - 23ms/epoch - 11ms/step\n",
      "Cummulative reward:  6\n",
      "\n",
      ">> Episode:  89 / 800\n",
      "2/2 - 0s - loss: 0.3347 - accuracy: 0.5781 - 24ms/epoch - 12ms/step\n",
      "Cummulative reward:  8\n",
      "\n",
      ">> Episode:  90 / 800\n",
      "2/2 - 0s - loss: 0.2891 - accuracy: 0.6719 - 23ms/epoch - 12ms/step\n",
      "Cummulative reward:  20\n",
      "\n",
      ">> Episode:  91 / 800\n",
      "2/2 - 0s - loss: 0.2979 - accuracy: 0.6562 - 24ms/epoch - 12ms/step\n",
      "Cummulative reward:  18\n",
      "\n",
      ">> Episode:  92 / 800\n",
      "2/2 - 0s - loss: 0.2644 - accuracy: 0.7031 - 21ms/epoch - 11ms/step\n",
      "Cummulative reward:  26\n",
      "\n",
      ">> Episode:  93 / 800\n",
      "2/2 - 0s - loss: 0.2855 - accuracy: 0.6250 - 22ms/epoch - 11ms/step\n",
      "Cummulative reward:  18\n",
      "\n",
      ">> Episode:  94 / 800\n",
      "2/2 - 0s - loss: 0.2636 - accuracy: 0.7031 - 22ms/epoch - 11ms/step\n",
      "Cummulative reward:  28\n",
      "\n",
      ">> Episode:  95 / 800\n",
      "2/2 - 0s - loss: 0.2227 - accuracy: 0.7656 - 23ms/epoch - 11ms/step\n",
      "Cummulative reward:  34\n",
      "\n",
      ">> Episode:  96 / 800\n",
      "2/2 - 0s - loss: 0.2628 - accuracy: 0.6719 - 22ms/epoch - 11ms/step\n",
      "Cummulative reward:  24\n",
      "\n",
      ">> Episode:  97 / 800\n",
      "2/2 - 0s - loss: 0.3078 - accuracy: 0.6406 - 23ms/epoch - 12ms/step\n",
      "Cummulative reward:  12\n",
      "\n",
      ">> Episode:  98 / 800\n",
      "2/2 - 0s - loss: 0.3188 - accuracy: 0.5625 - 24ms/epoch - 12ms/step\n",
      "Cummulative reward:  10\n",
      "\n",
      ">> Episode:  99 / 800\n",
      "2/2 - 0s - loss: 0.2625 - accuracy: 0.6719 - 21ms/epoch - 11ms/step\n",
      "Cummulative reward:  24\n",
      "\n",
      ">> Episode:  100 / 800\n",
      "2/2 - 0s - loss: 0.3127 - accuracy: 0.6250 - 24ms/epoch - 12ms/step\n",
      "Cummulative reward:  12\n",
      "\n",
      ">> Episode:  101 / 800\n",
      "2/2 - 0s - loss: 0.2747 - accuracy: 0.6719 - 28ms/epoch - 14ms/step\n",
      "Cummulative reward:  22\n",
      "\n",
      ">> Episode:  102 / 800\n",
      "2/2 - 0s - loss: 0.2839 - accuracy: 0.6719 - 24ms/epoch - 12ms/step\n",
      "Cummulative reward:  20\n",
      "\n",
      ">> Episode:  103 / 800\n",
      "2/2 - 0s - loss: 0.2218 - accuracy: 0.8281 - 22ms/epoch - 11ms/step\n",
      "Cummulative reward:  36\n",
      "\n",
      ">> Episode:  104 / 800\n",
      "2/2 - 0s - loss: 0.2850 - accuracy: 0.6719 - 23ms/epoch - 11ms/step\n",
      "Cummulative reward:  22\n",
      "\n",
      ">> Episode:  105 / 800\n",
      "2/2 - 0s - loss: 0.2457 - accuracy: 0.7500 - 24ms/epoch - 12ms/step\n",
      "Cummulative reward:  30\n",
      "\n",
      ">> Episode:  106 / 800\n",
      "2/2 - 0s - loss: 0.2672 - accuracy: 0.6719 - 24ms/epoch - 12ms/step\n",
      "Cummulative reward:  22\n",
      "\n",
      ">> Episode:  107 / 800\n",
      "2/2 - 0s - loss: 0.3368 - accuracy: 0.5469 - 23ms/epoch - 12ms/step\n",
      "Cummulative reward:  6\n",
      "\n",
      ">> Episode:  108 / 800\n",
      "2/2 - 0s - loss: 0.2777 - accuracy: 0.6875 - 23ms/epoch - 12ms/step\n",
      "Cummulative reward:  18\n",
      "\n",
      ">> Episode:  109 / 800\n",
      "2/2 - 0s - loss: 0.2936 - accuracy: 0.6094 - 24ms/epoch - 12ms/step\n",
      "Cummulative reward:  16\n",
      "\n",
      ">> Episode:  110 / 800\n",
      "2/2 - 0s - loss: 0.3312 - accuracy: 0.5938 - 25ms/epoch - 12ms/step\n",
      "Cummulative reward:  10\n",
      "\n",
      ">> Episode:  111 / 800\n",
      "2/2 - 0s - loss: 0.2652 - accuracy: 0.6875 - 23ms/epoch - 11ms/step\n",
      "Cummulative reward:  24\n",
      "\n",
      ">> Episode:  112 / 800\n",
      "2/2 - 0s - loss: 0.2570 - accuracy: 0.7344 - 24ms/epoch - 12ms/step\n",
      "Cummulative reward:  26\n",
      "\n",
      ">> Episode:  113 / 800\n",
      "2/2 - 0s - loss: 0.2587 - accuracy: 0.7031 - 25ms/epoch - 12ms/step\n",
      "Cummulative reward:  26\n",
      "\n",
      ">> Episode:  114 / 800\n",
      "2/2 - 0s - loss: 0.2938 - accuracy: 0.6406 - 25ms/epoch - 12ms/step\n",
      "Cummulative reward:  18\n",
      "\n",
      ">> Episode:  115 / 800\n",
      "2/2 - 0s - loss: 0.2645 - accuracy: 0.7188 - 23ms/epoch - 12ms/step\n",
      "Cummulative reward:  22\n",
      "\n",
      ">> Episode:  116 / 800\n",
      "2/2 - 0s - loss: 0.2354 - accuracy: 0.7656 - 25ms/epoch - 13ms/step\n",
      "Cummulative reward:  32\n",
      "\n",
      ">> Episode:  117 / 800\n",
      "2/2 - 0s - loss: 0.2622 - accuracy: 0.6875 - 24ms/epoch - 12ms/step\n",
      "Cummulative reward:  26\n",
      "\n",
      ">> Episode:  118 / 800\n",
      "2/2 - 0s - loss: 0.2632 - accuracy: 0.7031 - 24ms/epoch - 12ms/step\n",
      "Cummulative reward:  26\n",
      "\n",
      ">> Episode:  119 / 800\n",
      "2/2 - 0s - loss: 0.2642 - accuracy: 0.6562 - 24ms/epoch - 12ms/step\n",
      "Cummulative reward:  22\n",
      "\n",
      ">> Episode:  120 / 800\n",
      "2/2 - 0s - loss: 0.2800 - accuracy: 0.6719 - 25ms/epoch - 13ms/step\n",
      "Cummulative reward:  18\n",
      "\n",
      ">> Episode:  121 / 800\n",
      "2/2 - 0s - loss: 0.2120 - accuracy: 0.7656 - 24ms/epoch - 12ms/step\n",
      "Cummulative reward:  38\n",
      "\n",
      ">> Episode:  122 / 800\n",
      "2/2 - 0s - loss: 0.3143 - accuracy: 0.5938 - 33ms/epoch - 16ms/step\n",
      "Cummulative reward:  14\n",
      "\n",
      ">> Episode:  123 / 800\n",
      "2/2 - 0s - loss: 0.3233 - accuracy: 0.5781 - 48ms/epoch - 24ms/step\n",
      "Cummulative reward:  6\n",
      "\n",
      ">> Episode:  124 / 800\n",
      "2/2 - 0s - loss: 0.3102 - accuracy: 0.6250 - 26ms/epoch - 13ms/step\n",
      "Cummulative reward:  8\n",
      "\n",
      ">> Episode:  125 / 800\n",
      "2/2 - 0s - loss: 0.2803 - accuracy: 0.6094 - 24ms/epoch - 12ms/step\n",
      "Cummulative reward:  18\n",
      "\n",
      ">> Episode:  126 / 800\n",
      "2/2 - 0s - loss: 0.2770 - accuracy: 0.7188 - 24ms/epoch - 12ms/step\n",
      "Cummulative reward:  20\n",
      "\n",
      ">> Episode:  127 / 800\n",
      "2/2 - 0s - loss: 0.3147 - accuracy: 0.6094 - 33ms/epoch - 16ms/step\n",
      "Cummulative reward:  14\n",
      "\n",
      ">> Episode:  128 / 800\n",
      "2/2 - 0s - loss: 0.3085 - accuracy: 0.6094 - 30ms/epoch - 15ms/step\n",
      "Cummulative reward:  14\n",
      "\n",
      ">> Episode:  129 / 800\n",
      "2/2 - 0s - loss: 0.3501 - accuracy: 0.5469 - 25ms/epoch - 13ms/step\n",
      "Cummulative reward:  8\n",
      "\n",
      ">> Episode:  130 / 800\n",
      "2/2 - 0s - loss: 0.2853 - accuracy: 0.6562 - 28ms/epoch - 14ms/step\n",
      "Cummulative reward:  16\n",
      "\n",
      ">> Episode:  131 / 800\n",
      "2/2 - 0s - loss: 0.2841 - accuracy: 0.6250 - 26ms/epoch - 13ms/step\n",
      "Cummulative reward:  16\n",
      "\n",
      ">> Episode:  132 / 800\n",
      "2/2 - 0s - loss: 0.2966 - accuracy: 0.5938 - 28ms/epoch - 14ms/step\n",
      "Cummulative reward:  14\n",
      "\n",
      ">> Episode:  133 / 800\n",
      "2/2 - 0s - loss: 0.3178 - accuracy: 0.6094 - 32ms/epoch - 16ms/step\n",
      "Cummulative reward:  8\n",
      "\n",
      ">> Episode:  134 / 800\n",
      "2/2 - 0s - loss: 0.2597 - accuracy: 0.6875 - 26ms/epoch - 13ms/step\n",
      "Cummulative reward:  24\n",
      "\n",
      ">> Episode:  135 / 800\n",
      "2/2 - 0s - loss: 0.2540 - accuracy: 0.7188 - 34ms/epoch - 17ms/step\n",
      "Cummulative reward:  28\n",
      "\n",
      ">> Episode:  136 / 800\n",
      "2/2 - 0s - loss: 0.3087 - accuracy: 0.6406 - 27ms/epoch - 13ms/step\n",
      "Cummulative reward:  14\n",
      "\n",
      ">> Episode:  137 / 800\n",
      "2/2 - 0s - loss: 0.2085 - accuracy: 0.8125 - 52ms/epoch - 26ms/step\n",
      "Cummulative reward:  36\n",
      "\n",
      ">> Episode:  138 / 800\n",
      "2/2 - 0s - loss: 0.2922 - accuracy: 0.6719 - 27ms/epoch - 14ms/step\n",
      "Cummulative reward:  22\n",
      "\n",
      ">> Episode:  139 / 800\n",
      "2/2 - 0s - loss: 0.2923 - accuracy: 0.5938 - 27ms/epoch - 13ms/step\n",
      "Cummulative reward:  16\n",
      "\n",
      ">> Episode:  140 / 800\n",
      "2/2 - 0s - loss: 0.2850 - accuracy: 0.6406 - 29ms/epoch - 15ms/step\n",
      "Cummulative reward:  18\n",
      "\n",
      ">> Episode:  141 / 800\n",
      "2/2 - 0s - loss: 0.3135 - accuracy: 0.6094 - 24ms/epoch - 12ms/step\n",
      "Cummulative reward:  12\n",
      "\n",
      ">> Episode:  142 / 800\n",
      "2/2 - 0s - loss: 0.2953 - accuracy: 0.6094 - 27ms/epoch - 13ms/step\n",
      "Cummulative reward:  14\n",
      "\n",
      ">> Episode:  143 / 800\n",
      "2/2 - 0s - loss: 0.2809 - accuracy: 0.6406 - 25ms/epoch - 12ms/step\n",
      "Cummulative reward:  18\n",
      "\n",
      ">> Episode:  144 / 800\n",
      "2/2 - 0s - loss: 0.2340 - accuracy: 0.7969 - 26ms/epoch - 13ms/step\n",
      "Cummulative reward:  28\n",
      "\n",
      ">> Episode:  145 / 800\n",
      "2/2 - 0s - loss: 0.2584 - accuracy: 0.6719 - 29ms/epoch - 14ms/step\n",
      "Cummulative reward:  22\n",
      "\n",
      ">> Episode:  146 / 800\n",
      "2/2 - 0s - loss: 0.2552 - accuracy: 0.6875 - 28ms/epoch - 14ms/step\n",
      "Cummulative reward:  22\n",
      "\n",
      ">> Episode:  147 / 800\n",
      "2/2 - 0s - loss: 0.2520 - accuracy: 0.7031 - 30ms/epoch - 15ms/step\n",
      "Cummulative reward:  26\n",
      "\n",
      ">> Episode:  148 / 800\n",
      "2/2 - 0s - loss: 0.2372 - accuracy: 0.7031 - 29ms/epoch - 14ms/step\n",
      "Cummulative reward:  30\n",
      "\n",
      ">> Episode:  149 / 800\n",
      "2/2 - 0s - loss: 0.2262 - accuracy: 0.7812 - 26ms/epoch - 13ms/step\n",
      "Cummulative reward:  32\n",
      "\n",
      ">> Episode:  150 / 800\n",
      "2/2 - 0s - loss: 0.2302 - accuracy: 0.7656 - 34ms/epoch - 17ms/step\n",
      "Cummulative reward:  32\n",
      "\n",
      ">> Episode:  151 / 800\n",
      "2/2 - 0s - loss: 0.2451 - accuracy: 0.7344 - 26ms/epoch - 13ms/step\n",
      "Cummulative reward:  28\n",
      "\n",
      ">> Episode:  152 / 800\n",
      "2/2 - 0s - loss: 0.2914 - accuracy: 0.6719 - 32ms/epoch - 16ms/step\n",
      "Cummulative reward:  16\n",
      "\n",
      ">> Episode:  153 / 800\n",
      "2/2 - 0s - loss: 0.2317 - accuracy: 0.7188 - 28ms/epoch - 14ms/step\n",
      "Cummulative reward:  30\n",
      "\n",
      ">> Episode:  154 / 800\n",
      "2/2 - 0s - loss: 0.2643 - accuracy: 0.6562 - 26ms/epoch - 13ms/step\n",
      "Cummulative reward:  20\n",
      "\n",
      ">> Episode:  155 / 800\n",
      "2/2 - 0s - loss: 0.2186 - accuracy: 0.7344 - 27ms/epoch - 14ms/step\n",
      "Cummulative reward:  32\n",
      "\n",
      ">> Episode:  156 / 800\n",
      "2/2 - 0s - loss: 0.2765 - accuracy: 0.6875 - 29ms/epoch - 14ms/step\n",
      "Cummulative reward:  22\n",
      "\n",
      ">> Episode:  157 / 800\n",
      "2/2 - 0s - loss: 0.2472 - accuracy: 0.7031 - 29ms/epoch - 15ms/step\n",
      "Cummulative reward:  26\n",
      "\n",
      ">> Episode:  158 / 800\n",
      "2/2 - 0s - loss: 0.3242 - accuracy: 0.5781 - 37ms/epoch - 18ms/step\n",
      "Cummulative reward:  10\n",
      "\n",
      ">> Episode:  159 / 800\n",
      "2/2 - 0s - loss: 0.2594 - accuracy: 0.6719 - 26ms/epoch - 13ms/step\n",
      "Cummulative reward:  22\n",
      "\n",
      ">> Episode:  160 / 800\n",
      "2/2 - 0s - loss: 0.1759 - accuracy: 0.8594 - 29ms/epoch - 14ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  161 / 800\n",
      "2/2 - 0s - loss: 0.1842 - accuracy: 0.7969 - 44ms/epoch - 22ms/step\n",
      "Cummulative reward:  40\n",
      "\n",
      ">> Episode:  162 / 800\n",
      "2/2 - 0s - loss: 0.2956 - accuracy: 0.6562 - 53ms/epoch - 27ms/step\n",
      "Cummulative reward:  20\n",
      "\n",
      ">> Episode:  163 / 800\n",
      "2/2 - 0s - loss: 0.2188 - accuracy: 0.7344 - 49ms/epoch - 25ms/step\n",
      "Cummulative reward:  34\n",
      "\n",
      ">> Episode:  164 / 800\n",
      "2/2 - 0s - loss: 0.2560 - accuracy: 0.6875 - 27ms/epoch - 13ms/step\n",
      "Cummulative reward:  24\n",
      "\n",
      ">> Episode:  165 / 800\n",
      "2/2 - 0s - loss: 0.2037 - accuracy: 0.7969 - 30ms/epoch - 15ms/step\n",
      "Cummulative reward:  36\n",
      "\n",
      ">> Episode:  166 / 800\n",
      "2/2 - 0s - loss: 0.2882 - accuracy: 0.6406 - 28ms/epoch - 14ms/step\n",
      "Cummulative reward:  16\n",
      "\n",
      ">> Episode:  167 / 800\n",
      "2/2 - 0s - loss: 0.3290 - accuracy: 0.5781 - 26ms/epoch - 13ms/step\n",
      "Cummulative reward:  6\n",
      "\n",
      ">> Episode:  168 / 800\n",
      "2/2 - 0s - loss: 0.2130 - accuracy: 0.7500 - 27ms/epoch - 13ms/step\n",
      "Cummulative reward:  34\n",
      "\n",
      ">> Episode:  169 / 800\n",
      "2/2 - 0s - loss: 0.2159 - accuracy: 0.8125 - 28ms/epoch - 14ms/step\n",
      "Cummulative reward:  34\n",
      "\n",
      ">> Episode:  170 / 800\n",
      "2/2 - 0s - loss: 0.1849 - accuracy: 0.8750 - 26ms/epoch - 13ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  171 / 800\n",
      "2/2 - 0s - loss: 0.1972 - accuracy: 0.7969 - 27ms/epoch - 13ms/step\n",
      "Cummulative reward:  38\n",
      "\n",
      ">> Episode:  172 / 800\n",
      "2/2 - 0s - loss: 0.3058 - accuracy: 0.6562 - 28ms/epoch - 14ms/step\n",
      "Cummulative reward:  14\n",
      "\n",
      ">> Episode:  173 / 800\n",
      "2/2 - 0s - loss: 0.2068 - accuracy: 0.7656 - 29ms/epoch - 14ms/step\n",
      "Cummulative reward:  38\n",
      "\n",
      ">> Episode:  174 / 800\n",
      "2/2 - 0s - loss: 0.2126 - accuracy: 0.7344 - 29ms/epoch - 14ms/step\n",
      "Cummulative reward:  32\n",
      "\n",
      ">> Episode:  175 / 800\n",
      "2/2 - 0s - loss: 0.2939 - accuracy: 0.6250 - 27ms/epoch - 13ms/step\n",
      "Cummulative reward:  16\n",
      "\n",
      ">> Episode:  176 / 800\n",
      "2/2 - 0s - loss: 0.3028 - accuracy: 0.6719 - 38ms/epoch - 19ms/step\n",
      "Cummulative reward:  12\n",
      "\n",
      ">> Episode:  177 / 800\n",
      "2/2 - 0s - loss: 0.2067 - accuracy: 0.7812 - 31ms/epoch - 15ms/step\n",
      "Cummulative reward:  32\n",
      "\n",
      ">> Episode:  178 / 800\n",
      "2/2 - 0s - loss: 0.1613 - accuracy: 0.8281 - 28ms/epoch - 14ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  179 / 800\n",
      "2/2 - 0s - loss: 0.2150 - accuracy: 0.7500 - 29ms/epoch - 14ms/step\n",
      "Cummulative reward:  34\n",
      "\n",
      ">> Episode:  180 / 800\n",
      "2/2 - 0s - loss: 0.2616 - accuracy: 0.7031 - 48ms/epoch - 24ms/step\n",
      "Cummulative reward:  26\n",
      "\n",
      ">> Episode:  181 / 800\n",
      "2/2 - 0s - loss: 0.2462 - accuracy: 0.7344 - 37ms/epoch - 18ms/step\n",
      "Cummulative reward:  28\n",
      "\n",
      ">> Episode:  182 / 800\n",
      "2/2 - 0s - loss: 0.2593 - accuracy: 0.7031 - 36ms/epoch - 18ms/step\n",
      "Cummulative reward:  24\n",
      "\n",
      ">> Episode:  183 / 800\n",
      "2/2 - 0s - loss: 0.2216 - accuracy: 0.7656 - 47ms/epoch - 24ms/step\n",
      "Cummulative reward:  32\n",
      "\n",
      ">> Episode:  184 / 800\n",
      "2/2 - 0s - loss: 0.2209 - accuracy: 0.7188 - 40ms/epoch - 20ms/step\n",
      "Cummulative reward:  32\n",
      "\n",
      ">> Episode:  185 / 800\n",
      "2/2 - 0s - loss: 0.2665 - accuracy: 0.6406 - 31ms/epoch - 16ms/step\n",
      "Cummulative reward:  20\n",
      "\n",
      ">> Episode:  186 / 800\n",
      "2/2 - 0s - loss: 0.1966 - accuracy: 0.7500 - 30ms/epoch - 15ms/step\n",
      "Cummulative reward:  34\n",
      "\n",
      ">> Episode:  187 / 800\n",
      "2/2 - 0s - loss: 0.2811 - accuracy: 0.6406 - 29ms/epoch - 15ms/step\n",
      "Cummulative reward:  18\n",
      "\n",
      ">> Episode:  188 / 800\n",
      "2/2 - 0s - loss: 0.2111 - accuracy: 0.7500 - 35ms/epoch - 17ms/step\n",
      "Cummulative reward:  32\n",
      "\n",
      ">> Episode:  189 / 800\n",
      "2/2 - 0s - loss: 0.2145 - accuracy: 0.7344 - 29ms/epoch - 14ms/step\n",
      "Cummulative reward:  30\n",
      "\n",
      ">> Episode:  190 / 800\n",
      "2/2 - 0s - loss: 0.1630 - accuracy: 0.8750 - 32ms/epoch - 16ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  191 / 800\n",
      "2/2 - 0s - loss: 0.2290 - accuracy: 0.7188 - 28ms/epoch - 14ms/step\n",
      "Cummulative reward:  30\n",
      "\n",
      ">> Episode:  192 / 800\n",
      "2/2 - 0s - loss: 0.2510 - accuracy: 0.7188 - 28ms/epoch - 14ms/step\n",
      "Cummulative reward:  28\n",
      "\n",
      ">> Episode:  193 / 800\n",
      "2/2 - 0s - loss: 0.2020 - accuracy: 0.7812 - 29ms/epoch - 14ms/step\n",
      "Cummulative reward:  36\n",
      "\n",
      ">> Episode:  194 / 800\n",
      "2/2 - 0s - loss: 0.2666 - accuracy: 0.6562 - 28ms/epoch - 14ms/step\n",
      "Cummulative reward:  22\n",
      "\n",
      ">> Episode:  195 / 800\n",
      "2/2 - 0s - loss: 0.3057 - accuracy: 0.6250 - 29ms/epoch - 14ms/step\n",
      "Cummulative reward:  16\n",
      "\n",
      ">> Episode:  196 / 800\n",
      "2/2 - 0s - loss: 0.2264 - accuracy: 0.7656 - 28ms/epoch - 14ms/step\n",
      "Cummulative reward:  30\n",
      "\n",
      ">> Episode:  197 / 800\n",
      "2/2 - 0s - loss: 0.1859 - accuracy: 0.8125 - 34ms/epoch - 17ms/step\n",
      "Cummulative reward:  40\n",
      "\n",
      ">> Episode:  198 / 800\n",
      "2/2 - 0s - loss: 0.2658 - accuracy: 0.6719 - 29ms/epoch - 14ms/step\n",
      "Cummulative reward:  24\n",
      "\n",
      ">> Episode:  199 / 800\n",
      "2/2 - 0s - loss: 0.2799 - accuracy: 0.6719 - 29ms/epoch - 14ms/step\n",
      "Cummulative reward:  18\n",
      "\n",
      ">> Episode:  200 / 800\n",
      "2/2 - 0s - loss: 0.2074 - accuracy: 0.7812 - 29ms/epoch - 14ms/step\n",
      "Cummulative reward:  38\n",
      "\n",
      ">> Episode:  201 / 800\n",
      "2/2 - 0s - loss: 0.2464 - accuracy: 0.7188 - 32ms/epoch - 16ms/step\n",
      "Cummulative reward:  26\n",
      "\n",
      ">> Episode:  202 / 800\n",
      "2/2 - 0s - loss: 0.2194 - accuracy: 0.7500 - 40ms/epoch - 20ms/step\n",
      "Cummulative reward:  30\n",
      "\n",
      ">> Episode:  203 / 800\n",
      "2/2 - 0s - loss: 0.2406 - accuracy: 0.7500 - 40ms/epoch - 20ms/step\n",
      "Cummulative reward:  30\n",
      "\n",
      ">> Episode:  204 / 800\n",
      "2/2 - 0s - loss: 0.2989 - accuracy: 0.6719 - 36ms/epoch - 18ms/step\n",
      "Cummulative reward:  16\n",
      "\n",
      ">> Episode:  205 / 800\n",
      "2/2 - 0s - loss: 0.2171 - accuracy: 0.7812 - 33ms/epoch - 17ms/step\n",
      "Cummulative reward:  32\n",
      "\n",
      ">> Episode:  206 / 800\n",
      "2/2 - 0s - loss: 0.2936 - accuracy: 0.6562 - 35ms/epoch - 18ms/step\n",
      "Cummulative reward:  20\n",
      "\n",
      ">> Episode:  207 / 800\n",
      "2/2 - 0s - loss: 0.2776 - accuracy: 0.6719 - 36ms/epoch - 18ms/step\n",
      "Cummulative reward:  18\n",
      "\n",
      ">> Episode:  208 / 800\n",
      "2/2 - 0s - loss: 0.2141 - accuracy: 0.7500 - 30ms/epoch - 15ms/step\n",
      "Cummulative reward:  32\n",
      "\n",
      ">> Episode:  209 / 800\n",
      "2/2 - 0s - loss: 0.1385 - accuracy: 0.8750 - 32ms/epoch - 16ms/step\n",
      "Cummulative reward:  48\n",
      "\n",
      ">> Episode:  210 / 800\n",
      "2/2 - 0s - loss: 0.2082 - accuracy: 0.7812 - 30ms/epoch - 15ms/step\n",
      "Cummulative reward:  34\n",
      "\n",
      ">> Episode:  211 / 800\n",
      "2/2 - 0s - loss: 0.2864 - accuracy: 0.7188 - 30ms/epoch - 15ms/step\n",
      "Cummulative reward:  16\n",
      "\n",
      ">> Episode:  212 / 800\n",
      "2/2 - 0s - loss: 0.1577 - accuracy: 0.8438 - 31ms/epoch - 15ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  213 / 800\n",
      "2/2 - 0s - loss: 0.2174 - accuracy: 0.7656 - 46ms/epoch - 23ms/step\n",
      "Cummulative reward:  34\n",
      "\n",
      ">> Episode:  214 / 800\n",
      "2/2 - 0s - loss: 0.2242 - accuracy: 0.7812 - 32ms/epoch - 16ms/step\n",
      "Cummulative reward:  30\n",
      "\n",
      ">> Episode:  215 / 800\n",
      "2/2 - 0s - loss: 0.2673 - accuracy: 0.6719 - 29ms/epoch - 14ms/step\n",
      "Cummulative reward:  24\n",
      "\n",
      ">> Episode:  216 / 800\n",
      "2/2 - 0s - loss: 0.3041 - accuracy: 0.6250 - 47ms/epoch - 23ms/step\n",
      "Cummulative reward:  14\n",
      "\n",
      ">> Episode:  217 / 800\n",
      "2/2 - 0s - loss: 0.2645 - accuracy: 0.7188 - 29ms/epoch - 15ms/step\n",
      "Cummulative reward:  22\n",
      "\n",
      ">> Episode:  218 / 800\n",
      "2/2 - 0s - loss: 0.2164 - accuracy: 0.7812 - 28ms/epoch - 14ms/step\n",
      "Cummulative reward:  32\n",
      "\n",
      ">> Episode:  219 / 800\n",
      "2/2 - 0s - loss: 0.1583 - accuracy: 0.8750 - 27ms/epoch - 13ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  220 / 800\n",
      "2/2 - 0s - loss: 0.2077 - accuracy: 0.7500 - 27ms/epoch - 14ms/step\n",
      "Cummulative reward:  34\n",
      "\n",
      ">> Episode:  221 / 800\n",
      "2/2 - 0s - loss: 0.2367 - accuracy: 0.7500 - 28ms/epoch - 14ms/step\n",
      "Cummulative reward:  28\n",
      "\n",
      ">> Episode:  222 / 800\n",
      "2/2 - 0s - loss: 0.2211 - accuracy: 0.7656 - 27ms/epoch - 13ms/step\n",
      "Cummulative reward:  32\n",
      "\n",
      ">> Episode:  223 / 800\n",
      "2/2 - 0s - loss: 0.2151 - accuracy: 0.7500 - 29ms/epoch - 14ms/step\n",
      "Cummulative reward:  34\n",
      "\n",
      ">> Episode:  224 / 800\n",
      "2/2 - 0s - loss: 0.2171 - accuracy: 0.7344 - 29ms/epoch - 15ms/step\n",
      "Cummulative reward:  32\n",
      "\n",
      ">> Episode:  225 / 800\n",
      "2/2 - 0s - loss: 0.2048 - accuracy: 0.7344 - 31ms/epoch - 15ms/step\n",
      "Cummulative reward:  34\n",
      "\n",
      ">> Episode:  226 / 800\n",
      "2/2 - 0s - loss: 0.2020 - accuracy: 0.7500 - 41ms/epoch - 20ms/step\n",
      "Cummulative reward:  36\n",
      "\n",
      ">> Episode:  227 / 800\n",
      "2/2 - 0s - loss: 0.1430 - accuracy: 0.8438 - 32ms/epoch - 16ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  228 / 800\n",
      "2/2 - 0s - loss: 0.2087 - accuracy: 0.7656 - 30ms/epoch - 15ms/step\n",
      "Cummulative reward:  36\n",
      "\n",
      ">> Episode:  229 / 800\n",
      "2/2 - 0s - loss: 0.2661 - accuracy: 0.7031 - 28ms/epoch - 14ms/step\n",
      "Cummulative reward:  24\n",
      "\n",
      ">> Episode:  230 / 800\n",
      "2/2 - 0s - loss: 0.2231 - accuracy: 0.7344 - 28ms/epoch - 14ms/step\n",
      "Cummulative reward:  30\n",
      "\n",
      ">> Episode:  231 / 800\n",
      "2/2 - 0s - loss: 0.2116 - accuracy: 0.7656 - 29ms/epoch - 15ms/step\n",
      "Cummulative reward:  34\n",
      "\n",
      ">> Episode:  232 / 800\n",
      "2/2 - 0s - loss: 0.1769 - accuracy: 0.8125 - 31ms/epoch - 15ms/step\n",
      "Cummulative reward:  40\n",
      "\n",
      ">> Episode:  233 / 800\n",
      "2/2 - 0s - loss: 0.2589 - accuracy: 0.7031 - 30ms/epoch - 15ms/step\n",
      "Cummulative reward:  24\n",
      "\n",
      ">> Episode:  234 / 800\n",
      "2/2 - 0s - loss: 0.1860 - accuracy: 0.8125 - 34ms/epoch - 17ms/step\n",
      "Cummulative reward:  38\n",
      "\n",
      ">> Episode:  235 / 800\n",
      "2/2 - 0s - loss: 0.2004 - accuracy: 0.7812 - 29ms/epoch - 14ms/step\n",
      "Cummulative reward:  34\n",
      "\n",
      ">> Episode:  236 / 800\n",
      "2/2 - 0s - loss: 0.1981 - accuracy: 0.7969 - 30ms/epoch - 15ms/step\n",
      "Cummulative reward:  36\n",
      "\n",
      ">> Episode:  237 / 800\n",
      "2/2 - 0s - loss: 0.1890 - accuracy: 0.7812 - 31ms/epoch - 15ms/step\n",
      "Cummulative reward:  36\n",
      "\n",
      ">> Episode:  238 / 800\n",
      "2/2 - 0s - loss: 0.2152 - accuracy: 0.7812 - 30ms/epoch - 15ms/step\n",
      "Cummulative reward:  32\n",
      "\n",
      ">> Episode:  239 / 800\n",
      "2/2 - 0s - loss: 0.1332 - accuracy: 0.8594 - 29ms/epoch - 14ms/step\n",
      "Cummulative reward:  50\n",
      "\n",
      ">> Episode:  240 / 800\n",
      "2/2 - 0s - loss: 0.1729 - accuracy: 0.8281 - 30ms/epoch - 15ms/step\n",
      "Cummulative reward:  42\n",
      "\n",
      ">> Episode:  241 / 800\n",
      "2/2 - 0s - loss: 0.2120 - accuracy: 0.7500 - 30ms/epoch - 15ms/step\n",
      "Cummulative reward:  34\n",
      "\n",
      ">> Episode:  242 / 800\n",
      "2/2 - 0s - loss: 0.1800 - accuracy: 0.8281 - 32ms/epoch - 16ms/step\n",
      "Cummulative reward:  40\n",
      "\n",
      ">> Episode:  243 / 800\n",
      "2/2 - 0s - loss: 0.1460 - accuracy: 0.8750 - 29ms/epoch - 15ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  244 / 800\n",
      "2/2 - 0s - loss: 0.1312 - accuracy: 0.8750 - 29ms/epoch - 14ms/step\n",
      "Cummulative reward:  48\n",
      "\n",
      ">> Episode:  245 / 800\n",
      "2/2 - 0s - loss: 0.1502 - accuracy: 0.8594 - 31ms/epoch - 15ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  246 / 800\n",
      "2/2 - 0s - loss: 0.1783 - accuracy: 0.7969 - 41ms/epoch - 21ms/step\n",
      "Cummulative reward:  40\n",
      "\n",
      ">> Episode:  247 / 800\n",
      "2/2 - 0s - loss: 0.1728 - accuracy: 0.8125 - 31ms/epoch - 16ms/step\n",
      "Cummulative reward:  38\n",
      "\n",
      ">> Episode:  248 / 800\n",
      "2/2 - 0s - loss: 0.1916 - accuracy: 0.7656 - 33ms/epoch - 16ms/step\n",
      "Cummulative reward:  36\n",
      "\n",
      ">> Episode:  249 / 800\n",
      "2/2 - 0s - loss: 0.2143 - accuracy: 0.7656 - 30ms/epoch - 15ms/step\n",
      "Cummulative reward:  34\n",
      "\n",
      ">> Episode:  250 / 800\n",
      "2/2 - 0s - loss: 0.2662 - accuracy: 0.6875 - 28ms/epoch - 14ms/step\n",
      "Cummulative reward:  22\n",
      "\n",
      ">> Episode:  251 / 800\n",
      "2/2 - 0s - loss: 0.2235 - accuracy: 0.7500 - 29ms/epoch - 15ms/step\n",
      "Cummulative reward:  30\n",
      "\n",
      ">> Episode:  252 / 800\n",
      "2/2 - 0s - loss: 0.1580 - accuracy: 0.8438 - 35ms/epoch - 17ms/step\n",
      "Cummulative reward:  42\n",
      "\n",
      ">> Episode:  253 / 800\n",
      "2/2 - 0s - loss: 0.2389 - accuracy: 0.7344 - 33ms/epoch - 16ms/step\n",
      "Cummulative reward:  30\n",
      "\n",
      ">> Episode:  254 / 800\n",
      "2/2 - 0s - loss: 0.1845 - accuracy: 0.8125 - 31ms/epoch - 16ms/step\n",
      "Cummulative reward:  40\n",
      "\n",
      ">> Episode:  255 / 800\n",
      "2/2 - 0s - loss: 0.3478 - accuracy: 0.6094 - 34ms/epoch - 17ms/step\n",
      "Cummulative reward:  8\n",
      "\n",
      ">> Episode:  256 / 800\n",
      "2/2 - 0s - loss: 0.2442 - accuracy: 0.7500 - 30ms/epoch - 15ms/step\n",
      "Cummulative reward:  30\n",
      "\n",
      ">> Episode:  257 / 800\n",
      "2/2 - 0s - loss: 0.2196 - accuracy: 0.7344 - 31ms/epoch - 16ms/step\n",
      "Cummulative reward:  32\n",
      "\n",
      ">> Episode:  258 / 800\n",
      "2/2 - 0s - loss: 0.1731 - accuracy: 0.8125 - 39ms/epoch - 20ms/step\n",
      "Cummulative reward:  40\n",
      "\n",
      ">> Episode:  259 / 800\n",
      "2/2 - 0s - loss: 0.1869 - accuracy: 0.7812 - 32ms/epoch - 16ms/step\n",
      "Cummulative reward:  38\n",
      "\n",
      ">> Episode:  260 / 800\n",
      "2/2 - 0s - loss: 0.2537 - accuracy: 0.6875 - 31ms/epoch - 16ms/step\n",
      "Cummulative reward:  26\n",
      "\n",
      ">> Episode:  261 / 800\n",
      "2/2 - 0s - loss: 0.2906 - accuracy: 0.6562 - 33ms/epoch - 16ms/step\n",
      "Cummulative reward:  18\n",
      "\n",
      ">> Episode:  262 / 800\n",
      "2/2 - 0s - loss: 0.2318 - accuracy: 0.7500 - 34ms/epoch - 17ms/step\n",
      "Cummulative reward:  28\n",
      "\n",
      ">> Episode:  263 / 800\n",
      "2/2 - 0s - loss: 0.2232 - accuracy: 0.7344 - 32ms/epoch - 16ms/step\n",
      "Cummulative reward:  32\n",
      "\n",
      ">> Episode:  264 / 800\n",
      "2/2 - 0s - loss: 0.1711 - accuracy: 0.8281 - 39ms/epoch - 19ms/step\n",
      "Cummulative reward:  42\n",
      "\n",
      ">> Episode:  265 / 800\n",
      "2/2 - 0s - loss: 0.2196 - accuracy: 0.7656 - 33ms/epoch - 16ms/step\n",
      "Cummulative reward:  32\n",
      "\n",
      ">> Episode:  266 / 800\n",
      "2/2 - 0s - loss: 0.2165 - accuracy: 0.7656 - 30ms/epoch - 15ms/step\n",
      "Cummulative reward:  32\n",
      "\n",
      ">> Episode:  267 / 800\n",
      "2/2 - 0s - loss: 0.2359 - accuracy: 0.7344 - 33ms/epoch - 16ms/step\n",
      "Cummulative reward:  30\n",
      "\n",
      ">> Episode:  268 / 800\n",
      "2/2 - 0s - loss: 0.2528 - accuracy: 0.7031 - 32ms/epoch - 16ms/step\n",
      "Cummulative reward:  26\n",
      "\n",
      ">> Episode:  269 / 800\n",
      "2/2 - 0s - loss: 0.2433 - accuracy: 0.7344 - 33ms/epoch - 17ms/step\n",
      "Cummulative reward:  26\n",
      "\n",
      ">> Episode:  270 / 800\n",
      "2/2 - 0s - loss: 0.1608 - accuracy: 0.8750 - 34ms/epoch - 17ms/step\n",
      "Cummulative reward:  42\n",
      "\n",
      ">> Episode:  271 / 800\n",
      "2/2 - 0s - loss: 0.1539 - accuracy: 0.8750 - 32ms/epoch - 16ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  272 / 800\n",
      "2/2 - 0s - loss: 0.1706 - accuracy: 0.8125 - 33ms/epoch - 17ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  273 / 800\n",
      "2/2 - 0s - loss: 0.1439 - accuracy: 0.8750 - 39ms/epoch - 20ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  274 / 800\n",
      "2/2 - 0s - loss: 0.1469 - accuracy: 0.8594 - 34ms/epoch - 17ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  275 / 800\n",
      "2/2 - 0s - loss: 0.1725 - accuracy: 0.8125 - 31ms/epoch - 15ms/step\n",
      "Cummulative reward:  42\n",
      "\n",
      ">> Episode:  276 / 800\n",
      "2/2 - 0s - loss: 0.1475 - accuracy: 0.8594 - 32ms/epoch - 16ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  277 / 800\n",
      "2/2 - 0s - loss: 0.1965 - accuracy: 0.7969 - 36ms/epoch - 18ms/step\n",
      "Cummulative reward:  36\n",
      "\n",
      ">> Episode:  278 / 800\n",
      "2/2 - 0s - loss: 0.2318 - accuracy: 0.7344 - 36ms/epoch - 18ms/step\n",
      "Cummulative reward:  26\n",
      "\n",
      ">> Episode:  279 / 800\n",
      "2/2 - 0s - loss: 0.2538 - accuracy: 0.7188 - 32ms/epoch - 16ms/step\n",
      "Cummulative reward:  26\n",
      "\n",
      ">> Episode:  280 / 800\n",
      "2/2 - 0s - loss: 0.2833 - accuracy: 0.6562 - 32ms/epoch - 16ms/step\n",
      "Cummulative reward:  22\n",
      "\n",
      ">> Episode:  281 / 800\n",
      "2/2 - 0s - loss: 0.1677 - accuracy: 0.8438 - 42ms/epoch - 21ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  282 / 800\n",
      "2/2 - 0s - loss: 0.1479 - accuracy: 0.8594 - 41ms/epoch - 21ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  283 / 800\n",
      "2/2 - 0s - loss: 0.2044 - accuracy: 0.7500 - 43ms/epoch - 22ms/step\n",
      "Cummulative reward:  32\n",
      "\n",
      ">> Episode:  284 / 800\n",
      "2/2 - 0s - loss: 0.2240 - accuracy: 0.7656 - 36ms/epoch - 18ms/step\n",
      "Cummulative reward:  30\n",
      "\n",
      ">> Episode:  285 / 800\n",
      "2/2 - 0s - loss: 0.2129 - accuracy: 0.7812 - 44ms/epoch - 22ms/step\n",
      "Cummulative reward:  36\n",
      "\n",
      ">> Episode:  286 / 800\n",
      "2/2 - 0s - loss: 0.2314 - accuracy: 0.7031 - 46ms/epoch - 23ms/step\n",
      "Cummulative reward:  28\n",
      "\n",
      ">> Episode:  287 / 800\n",
      "2/2 - 0s - loss: 0.1859 - accuracy: 0.7656 - 37ms/epoch - 19ms/step\n",
      "Cummulative reward:  36\n",
      "\n",
      ">> Episode:  288 / 800\n",
      "2/2 - 0s - loss: 0.1323 - accuracy: 0.8750 - 44ms/epoch - 22ms/step\n",
      "Cummulative reward:  48\n",
      "\n",
      ">> Episode:  289 / 800\n",
      "2/2 - 0s - loss: 0.1874 - accuracy: 0.7969 - 40ms/epoch - 20ms/step\n",
      "Cummulative reward:  40\n",
      "\n",
      ">> Episode:  290 / 800\n",
      "2/2 - 0s - loss: 0.2523 - accuracy: 0.7188 - 41ms/epoch - 21ms/step\n",
      "Cummulative reward:  28\n",
      "\n",
      ">> Episode:  291 / 800\n",
      "2/2 - 0s - loss: 0.2432 - accuracy: 0.7344 - 37ms/epoch - 18ms/step\n",
      "Cummulative reward:  30\n",
      "\n",
      ">> Episode:  292 / 800\n",
      "2/2 - 0s - loss: 0.1960 - accuracy: 0.7812 - 34ms/epoch - 17ms/step\n",
      "Cummulative reward:  34\n",
      "\n",
      ">> Episode:  293 / 800\n",
      "2/2 - 0s - loss: 0.2169 - accuracy: 0.7500 - 37ms/epoch - 19ms/step\n",
      "Cummulative reward:  32\n",
      "\n",
      ">> Episode:  294 / 800\n",
      "2/2 - 0s - loss: 0.1386 - accuracy: 0.8750 - 41ms/epoch - 20ms/step\n",
      "Cummulative reward:  48\n",
      "\n",
      ">> Episode:  295 / 800\n",
      "2/2 - 0s - loss: 0.1651 - accuracy: 0.8281 - 38ms/epoch - 19ms/step\n",
      "Cummulative reward:  42\n",
      "\n",
      ">> Episode:  296 / 800\n",
      "2/2 - 0s - loss: 0.2129 - accuracy: 0.7656 - 37ms/epoch - 19ms/step\n",
      "Cummulative reward:  32\n",
      "\n",
      ">> Episode:  297 / 800\n",
      "2/2 - 0s - loss: 0.1670 - accuracy: 0.8281 - 45ms/epoch - 23ms/step\n",
      "Cummulative reward:  42\n",
      "\n",
      ">> Episode:  298 / 800\n",
      "2/2 - 0s - loss: 0.2074 - accuracy: 0.7812 - 38ms/epoch - 19ms/step\n",
      "Cummulative reward:  34\n",
      "\n",
      ">> Episode:  299 / 800\n",
      "2/2 - 0s - loss: 0.1876 - accuracy: 0.8125 - 33ms/epoch - 16ms/step\n",
      "Cummulative reward:  34\n",
      "\n",
      ">> Episode:  300 / 800\n",
      "2/2 - 0s - loss: 0.1638 - accuracy: 0.7969 - 44ms/epoch - 22ms/step\n",
      "Cummulative reward:  42\n",
      "\n",
      ">> Episode:  301 / 800\n",
      "2/2 - 0s - loss: 0.2091 - accuracy: 0.7656 - 52ms/epoch - 26ms/step\n",
      "Cummulative reward:  32\n",
      "\n",
      ">> Episode:  302 / 800\n",
      "2/2 - 0s - loss: 0.2280 - accuracy: 0.7500 - 38ms/epoch - 19ms/step\n",
      "Cummulative reward:  32\n",
      "\n",
      ">> Episode:  303 / 800\n",
      "2/2 - 0s - loss: 0.2342 - accuracy: 0.7344 - 32ms/epoch - 16ms/step\n",
      "Cummulative reward:  30\n",
      "\n",
      ">> Episode:  304 / 800\n",
      "2/2 - 0s - loss: 0.2618 - accuracy: 0.7031 - 38ms/epoch - 19ms/step\n",
      "Cummulative reward:  26\n",
      "\n",
      ">> Episode:  305 / 800\n",
      "2/2 - 0s - loss: 0.2334 - accuracy: 0.7500 - 40ms/epoch - 20ms/step\n",
      "Cummulative reward:  26\n",
      "\n",
      ">> Episode:  306 / 800\n",
      "2/2 - 0s - loss: 0.2248 - accuracy: 0.7188 - 39ms/epoch - 19ms/step\n",
      "Cummulative reward:  32\n",
      "\n",
      ">> Episode:  307 / 800\n",
      "2/2 - 0s - loss: 0.1239 - accuracy: 0.8906 - 37ms/epoch - 18ms/step\n",
      "Cummulative reward:  50\n",
      "\n",
      ">> Episode:  308 / 800\n",
      "2/2 - 0s - loss: 0.1854 - accuracy: 0.8125 - 40ms/epoch - 20ms/step\n",
      "Cummulative reward:  38\n",
      "\n",
      ">> Episode:  309 / 800\n",
      "2/2 - 0s - loss: 0.1844 - accuracy: 0.8125 - 40ms/epoch - 20ms/step\n",
      "Cummulative reward:  36\n",
      "\n",
      ">> Episode:  310 / 800\n",
      "2/2 - 0s - loss: 0.2192 - accuracy: 0.7656 - 36ms/epoch - 18ms/step\n",
      "Cummulative reward:  32\n",
      "\n",
      ">> Episode:  311 / 800\n",
      "2/2 - 0s - loss: 0.1607 - accuracy: 0.8125 - 32ms/epoch - 16ms/step\n",
      "Cummulative reward:  40\n",
      "\n",
      ">> Episode:  312 / 800\n",
      "2/2 - 0s - loss: 0.1792 - accuracy: 0.8125 - 44ms/epoch - 22ms/step\n",
      "Cummulative reward:  38\n",
      "\n",
      ">> Episode:  313 / 800\n",
      "2/2 - 0s - loss: 0.1933 - accuracy: 0.7656 - 32ms/epoch - 16ms/step\n",
      "Cummulative reward:  34\n",
      "\n",
      ">> Episode:  314 / 800\n",
      "2/2 - 0s - loss: 0.2419 - accuracy: 0.7344 - 33ms/epoch - 17ms/step\n",
      "Cummulative reward:  28\n",
      "\n",
      ">> Episode:  315 / 800\n",
      "2/2 - 0s - loss: 0.1758 - accuracy: 0.7969 - 32ms/epoch - 16ms/step\n",
      "Cummulative reward:  36\n",
      "\n",
      ">> Episode:  316 / 800\n",
      "2/2 - 0s - loss: 0.2079 - accuracy: 0.7812 - 37ms/epoch - 19ms/step\n",
      "Cummulative reward:  34\n",
      "\n",
      ">> Episode:  317 / 800\n",
      "2/2 - 0s - loss: 0.2321 - accuracy: 0.7344 - 37ms/epoch - 19ms/step\n",
      "Cummulative reward:  30\n",
      "\n",
      ">> Episode:  318 / 800\n",
      "2/2 - 0s - loss: 0.1841 - accuracy: 0.7656 - 47ms/epoch - 23ms/step\n",
      "Cummulative reward:  36\n",
      "\n",
      ">> Episode:  319 / 800\n",
      "2/2 - 0s - loss: 0.2149 - accuracy: 0.7812 - 40ms/epoch - 20ms/step\n",
      "Cummulative reward:  30\n",
      "\n",
      ">> Episode:  320 / 800\n",
      "2/2 - 0s - loss: 0.1550 - accuracy: 0.8594 - 36ms/epoch - 18ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  321 / 800\n",
      "2/2 - 0s - loss: 0.2265 - accuracy: 0.7656 - 44ms/epoch - 22ms/step\n",
      "Cummulative reward:  30\n",
      "\n",
      ">> Episode:  322 / 800\n",
      "2/2 - 0s - loss: 0.1550 - accuracy: 0.8594 - 35ms/epoch - 18ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  323 / 800\n",
      "2/2 - 0s - loss: 0.1920 - accuracy: 0.8125 - 35ms/epoch - 18ms/step\n",
      "Cummulative reward:  38\n",
      "\n",
      ">> Episode:  324 / 800\n",
      "2/2 - 0s - loss: 0.2076 - accuracy: 0.7812 - 42ms/epoch - 21ms/step\n",
      "Cummulative reward:  36\n",
      "\n",
      ">> Episode:  325 / 800\n",
      "2/2 - 0s - loss: 0.2244 - accuracy: 0.7500 - 38ms/epoch - 19ms/step\n",
      "Cummulative reward:  32\n",
      "\n",
      ">> Episode:  326 / 800\n",
      "2/2 - 0s - loss: 0.2056 - accuracy: 0.7969 - 38ms/epoch - 19ms/step\n",
      "Cummulative reward:  34\n",
      "\n",
      ">> Episode:  327 / 800\n",
      "2/2 - 0s - loss: 0.1533 - accuracy: 0.8125 - 43ms/epoch - 21ms/step\n",
      "Cummulative reward:  40\n",
      "\n",
      ">> Episode:  328 / 800\n",
      "2/2 - 0s - loss: 0.1669 - accuracy: 0.8281 - 47ms/epoch - 23ms/step\n",
      "Cummulative reward:  40\n",
      "\n",
      ">> Episode:  329 / 800\n",
      "2/2 - 0s - loss: 0.1390 - accuracy: 0.8594 - 45ms/epoch - 22ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  330 / 800\n",
      "2/2 - 0s - loss: 0.1809 - accuracy: 0.8281 - 42ms/epoch - 21ms/step\n",
      "Cummulative reward:  42\n",
      "\n",
      ">> Episode:  331 / 800\n",
      "2/2 - 0s - loss: 0.2123 - accuracy: 0.7656 - 38ms/epoch - 19ms/step\n",
      "Cummulative reward:  32\n",
      "\n",
      ">> Episode:  332 / 800\n",
      "2/2 - 0s - loss: 0.1506 - accuracy: 0.8438 - 54ms/epoch - 27ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  333 / 800\n",
      "2/2 - 0s - loss: 0.1483 - accuracy: 0.8438 - 44ms/epoch - 22ms/step\n",
      "Cummulative reward:  42\n",
      "\n",
      ">> Episode:  334 / 800\n",
      "2/2 - 0s - loss: 0.1652 - accuracy: 0.8281 - 39ms/epoch - 19ms/step\n",
      "Cummulative reward:  42\n",
      "\n",
      ">> Episode:  335 / 800\n",
      "2/2 - 0s - loss: 0.2047 - accuracy: 0.7812 - 36ms/epoch - 18ms/step\n",
      "Cummulative reward:  34\n",
      "\n",
      ">> Episode:  336 / 800\n",
      "2/2 - 0s - loss: 0.1729 - accuracy: 0.7969 - 41ms/epoch - 20ms/step\n",
      "Cummulative reward:  36\n",
      "\n",
      ">> Episode:  337 / 800\n",
      "2/2 - 0s - loss: 0.1504 - accuracy: 0.8281 - 45ms/epoch - 22ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  338 / 800\n",
      "2/2 - 0s - loss: 0.1595 - accuracy: 0.8438 - 38ms/epoch - 19ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  339 / 800\n",
      "2/2 - 0s - loss: 0.2058 - accuracy: 0.7969 - 42ms/epoch - 21ms/step\n",
      "Cummulative reward:  36\n",
      "\n",
      ">> Episode:  340 / 800\n",
      "2/2 - 0s - loss: 0.1686 - accuracy: 0.8281 - 36ms/epoch - 18ms/step\n",
      "Cummulative reward:  40\n",
      "\n",
      ">> Episode:  341 / 800\n",
      "2/2 - 0s - loss: 0.1465 - accuracy: 0.8594 - 64ms/epoch - 32ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  342 / 800\n",
      "2/2 - 0s - loss: 0.1862 - accuracy: 0.7812 - 50ms/epoch - 25ms/step\n",
      "Cummulative reward:  38\n",
      "\n",
      ">> Episode:  343 / 800\n",
      "2/2 - 0s - loss: 0.2683 - accuracy: 0.6875 - 41ms/epoch - 20ms/step\n",
      "Cummulative reward:  24\n",
      "\n",
      ">> Episode:  344 / 800\n",
      "2/2 - 0s - loss: 0.1301 - accuracy: 0.8750 - 36ms/epoch - 18ms/step\n",
      "Cummulative reward:  48\n",
      "\n",
      ">> Episode:  345 / 800\n",
      "2/2 - 0s - loss: 0.1820 - accuracy: 0.8281 - 53ms/epoch - 26ms/step\n",
      "Cummulative reward:  40\n",
      "\n",
      ">> Episode:  346 / 800\n",
      "2/2 - 0s - loss: 0.1309 - accuracy: 0.8906 - 49ms/epoch - 24ms/step\n",
      "Cummulative reward:  50\n",
      "\n",
      ">> Episode:  347 / 800\n",
      "2/2 - 0s - loss: 0.1727 - accuracy: 0.7969 - 40ms/epoch - 20ms/step\n",
      "Cummulative reward:  38\n",
      "\n",
      ">> Episode:  348 / 800\n",
      "2/2 - 0s - loss: 0.2277 - accuracy: 0.7656 - 40ms/epoch - 20ms/step\n",
      "Cummulative reward:  28\n",
      "\n",
      ">> Episode:  349 / 800\n",
      "2/2 - 0s - loss: 0.1576 - accuracy: 0.8281 - 38ms/epoch - 19ms/step\n",
      "Cummulative reward:  42\n",
      "\n",
      ">> Episode:  350 / 800\n",
      "2/2 - 0s - loss: 0.2379 - accuracy: 0.7500 - 34ms/epoch - 17ms/step\n",
      "Cummulative reward:  30\n",
      "\n",
      ">> Episode:  351 / 800\n",
      "2/2 - 0s - loss: 0.1422 - accuracy: 0.8438 - 37ms/epoch - 19ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  352 / 800\n",
      "2/2 - 0s - loss: 0.2012 - accuracy: 0.7812 - 42ms/epoch - 21ms/step\n",
      "Cummulative reward:  34\n",
      "\n",
      ">> Episode:  353 / 800\n",
      "2/2 - 0s - loss: 0.2059 - accuracy: 0.7656 - 39ms/epoch - 20ms/step\n",
      "Cummulative reward:  34\n",
      "\n",
      ">> Episode:  354 / 800\n",
      "2/2 - 0s - loss: 0.2117 - accuracy: 0.8125 - 38ms/epoch - 19ms/step\n",
      "Cummulative reward:  30\n",
      "\n",
      ">> Episode:  355 / 800\n",
      "2/2 - 0s - loss: 0.1300 - accuracy: 0.8750 - 47ms/epoch - 23ms/step\n",
      "Cummulative reward:  48\n",
      "\n",
      ">> Episode:  356 / 800\n",
      "2/2 - 0s - loss: 0.1233 - accuracy: 0.8906 - 43ms/epoch - 21ms/step\n",
      "Cummulative reward:  50\n",
      "\n",
      ">> Episode:  357 / 800\n",
      "2/2 - 0s - loss: 0.1384 - accuracy: 0.8594 - 47ms/epoch - 23ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  358 / 800\n",
      "2/2 - 0s - loss: 0.1345 - accuracy: 0.8750 - 41ms/epoch - 20ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  359 / 800\n",
      "2/2 - 0s - loss: 0.1198 - accuracy: 0.8750 - 39ms/epoch - 20ms/step\n",
      "Cummulative reward:  50\n",
      "\n",
      ">> Episode:  360 / 800\n",
      "2/2 - 0s - loss: 0.2038 - accuracy: 0.7656 - 98ms/epoch - 49ms/step\n",
      "Cummulative reward:  36\n",
      "\n",
      ">> Episode:  361 / 800\n",
      "2/2 - 0s - loss: 0.2162 - accuracy: 0.7656 - 50ms/epoch - 25ms/step\n",
      "Cummulative reward:  34\n",
      "\n",
      ">> Episode:  362 / 800\n",
      "2/2 - 0s - loss: 0.2188 - accuracy: 0.7812 - 52ms/epoch - 26ms/step\n",
      "Cummulative reward:  36\n",
      "\n",
      ">> Episode:  363 / 800\n",
      "2/2 - 0s - loss: 0.1153 - accuracy: 0.8750 - 44ms/epoch - 22ms/step\n",
      "Cummulative reward:  48\n",
      "\n",
      ">> Episode:  364 / 800\n",
      "2/2 - 0s - loss: 0.1618 - accuracy: 0.8438 - 40ms/epoch - 20ms/step\n",
      "Cummulative reward:  42\n",
      "\n",
      ">> Episode:  365 / 800\n",
      "2/2 - 0s - loss: 0.1942 - accuracy: 0.7969 - 42ms/epoch - 21ms/step\n",
      "Cummulative reward:  32\n",
      "\n",
      ">> Episode:  366 / 800\n",
      "2/2 - 0s - loss: 0.1596 - accuracy: 0.8438 - 38ms/epoch - 19ms/step\n",
      "Cummulative reward:  42\n",
      "\n",
      ">> Episode:  367 / 800\n",
      "2/2 - 0s - loss: 0.1377 - accuracy: 0.8750 - 74ms/epoch - 37ms/step\n",
      "Cummulative reward:  48\n",
      "\n",
      ">> Episode:  368 / 800\n",
      "2/2 - 0s - loss: 0.1839 - accuracy: 0.7969 - 45ms/epoch - 22ms/step\n",
      "Cummulative reward:  40\n",
      "\n",
      ">> Episode:  369 / 800\n",
      "2/2 - 0s - loss: 0.1721 - accuracy: 0.8125 - 39ms/epoch - 20ms/step\n",
      "Cummulative reward:  40\n",
      "\n",
      ">> Episode:  370 / 800\n",
      "2/2 - 0s - loss: 0.2144 - accuracy: 0.7656 - 40ms/epoch - 20ms/step\n",
      "Cummulative reward:  34\n",
      "\n",
      ">> Episode:  371 / 800\n",
      "2/2 - 0s - loss: 0.1218 - accuracy: 0.8906 - 39ms/epoch - 20ms/step\n",
      "Cummulative reward:  50\n",
      "\n",
      ">> Episode:  372 / 800\n",
      "2/2 - 0s - loss: 0.1771 - accuracy: 0.7969 - 40ms/epoch - 20ms/step\n",
      "Cummulative reward:  38\n",
      "\n",
      ">> Episode:  373 / 800\n",
      "2/2 - 0s - loss: 0.2204 - accuracy: 0.7500 - 41ms/epoch - 20ms/step\n",
      "Cummulative reward:  28\n",
      "\n",
      ">> Episode:  374 / 800\n",
      "2/2 - 0s - loss: 0.1782 - accuracy: 0.8438 - 70ms/epoch - 35ms/step\n",
      "Cummulative reward:  42\n",
      "\n",
      ">> Episode:  375 / 800\n",
      "2/2 - 0s - loss: 0.1904 - accuracy: 0.8281 - 54ms/epoch - 27ms/step\n",
      "Cummulative reward:  34\n",
      "\n",
      ">> Episode:  376 / 800\n",
      "2/2 - 0s - loss: 0.1471 - accuracy: 0.8594 - 38ms/epoch - 19ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  377 / 800\n",
      "2/2 - 0s - loss: 0.1350 - accuracy: 0.8594 - 46ms/epoch - 23ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  378 / 800\n",
      "2/2 - 0s - loss: 0.1596 - accuracy: 0.8281 - 42ms/epoch - 21ms/step\n",
      "Cummulative reward:  40\n",
      "\n",
      ">> Episode:  379 / 800\n",
      "2/2 - 0s - loss: 0.1356 - accuracy: 0.8438 - 36ms/epoch - 18ms/step\n",
      "Cummulative reward:  48\n",
      "\n",
      ">> Episode:  380 / 800\n",
      "2/2 - 0s - loss: 0.1742 - accuracy: 0.8125 - 39ms/epoch - 20ms/step\n",
      "Cummulative reward:  38\n",
      "\n",
      ">> Episode:  381 / 800\n",
      "2/2 - 0s - loss: 0.1172 - accuracy: 0.8906 - 46ms/epoch - 23ms/step\n",
      "Cummulative reward:  48\n",
      "\n",
      ">> Episode:  382 / 800\n",
      "2/2 - 0s - loss: 0.1531 - accuracy: 0.8594 - 41ms/epoch - 21ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  383 / 800\n",
      "2/2 - 0s - loss: 0.1990 - accuracy: 0.7969 - 39ms/epoch - 20ms/step\n",
      "Cummulative reward:  38\n",
      "\n",
      ">> Episode:  384 / 800\n",
      "2/2 - 0s - loss: 0.1531 - accuracy: 0.8750 - 41ms/epoch - 20ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  385 / 800\n",
      "2/2 - 0s - loss: 0.0799 - accuracy: 0.9688 - 44ms/epoch - 22ms/step\n",
      "Cummulative reward:  58\n",
      "\n",
      ">> Episode:  386 / 800\n",
      "2/2 - 0s - loss: 0.1541 - accuracy: 0.8125 - 42ms/epoch - 21ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  387 / 800\n",
      "2/2 - 0s - loss: 0.1588 - accuracy: 0.8281 - 44ms/epoch - 22ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  388 / 800\n",
      "2/2 - 0s - loss: 0.1836 - accuracy: 0.7969 - 39ms/epoch - 19ms/step\n",
      "Cummulative reward:  36\n",
      "\n",
      ">> Episode:  389 / 800\n",
      "2/2 - 0s - loss: 0.2054 - accuracy: 0.7656 - 42ms/epoch - 21ms/step\n",
      "Cummulative reward:  34\n",
      "\n",
      ">> Episode:  390 / 800\n",
      "2/2 - 0s - loss: 0.1425 - accuracy: 0.8594 - 40ms/epoch - 20ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  391 / 800\n",
      "2/2 - 0s - loss: 0.1951 - accuracy: 0.7969 - 56ms/epoch - 28ms/step\n",
      "Cummulative reward:  38\n",
      "\n",
      ">> Episode:  392 / 800\n",
      "2/2 - 0s - loss: 0.1517 - accuracy: 0.8594 - 40ms/epoch - 20ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  393 / 800\n",
      "2/2 - 0s - loss: 0.1226 - accuracy: 0.9062 - 39ms/epoch - 19ms/step\n",
      "Cummulative reward:  50\n",
      "\n",
      ">> Episode:  394 / 800\n",
      "2/2 - 0s - loss: 0.1991 - accuracy: 0.7344 - 39ms/epoch - 20ms/step\n",
      "Cummulative reward:  30\n",
      "\n",
      ">> Episode:  395 / 800\n",
      "2/2 - 0s - loss: 0.2210 - accuracy: 0.7344 - 39ms/epoch - 19ms/step\n",
      "Cummulative reward:  30\n",
      "\n",
      ">> Episode:  396 / 800\n",
      "2/2 - 0s - loss: 0.1304 - accuracy: 0.8750 - 42ms/epoch - 21ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  397 / 800\n",
      "2/2 - 0s - loss: 0.2129 - accuracy: 0.7812 - 42ms/epoch - 21ms/step\n",
      "Cummulative reward:  32\n",
      "\n",
      ">> Episode:  398 / 800\n",
      "2/2 - 0s - loss: 0.1631 - accuracy: 0.8281 - 40ms/epoch - 20ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  399 / 800\n",
      "2/2 - 0s - loss: 0.1786 - accuracy: 0.7969 - 43ms/epoch - 21ms/step\n",
      "Cummulative reward:  36\n",
      "\n",
      ">> Episode:  400 / 800\n",
      "2/2 - 0s - loss: 0.1572 - accuracy: 0.8125 - 42ms/epoch - 21ms/step\n",
      "Cummulative reward:  42\n",
      "\n",
      ">> Episode:  401 / 800\n",
      "2/2 - 0s - loss: 0.1182 - accuracy: 0.8906 - 42ms/epoch - 21ms/step\n",
      "Cummulative reward:  48\n",
      "\n",
      ">> Episode:  402 / 800\n",
      "2/2 - 0s - loss: 0.2035 - accuracy: 0.7500 - 39ms/epoch - 20ms/step\n",
      "Cummulative reward:  34\n",
      "\n",
      ">> Episode:  403 / 800\n",
      "2/2 - 0s - loss: 0.1087 - accuracy: 0.9062 - 40ms/epoch - 20ms/step\n",
      "Cummulative reward:  50\n",
      "\n",
      ">> Episode:  404 / 800\n",
      "2/2 - 0s - loss: 0.1904 - accuracy: 0.7969 - 41ms/epoch - 20ms/step\n",
      "Cummulative reward:  38\n",
      "\n",
      ">> Episode:  405 / 800\n",
      "2/2 - 0s - loss: 0.1435 - accuracy: 0.8438 - 41ms/epoch - 21ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  406 / 800\n",
      "2/2 - 0s - loss: 0.1559 - accuracy: 0.8281 - 40ms/epoch - 20ms/step\n",
      "Cummulative reward:  42\n",
      "\n",
      ">> Episode:  407 / 800\n",
      "2/2 - 0s - loss: 0.1454 - accuracy: 0.8281 - 44ms/epoch - 22ms/step\n",
      "Cummulative reward:  42\n",
      "\n",
      ">> Episode:  408 / 800\n",
      "2/2 - 0s - loss: 0.1573 - accuracy: 0.8594 - 43ms/epoch - 21ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  409 / 800\n",
      "2/2 - 0s - loss: 0.1271 - accuracy: 0.8906 - 41ms/epoch - 21ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  410 / 800\n",
      "2/2 - 0s - loss: 0.1907 - accuracy: 0.7812 - 41ms/epoch - 21ms/step\n",
      "Cummulative reward:  36\n",
      "\n",
      ">> Episode:  411 / 800\n",
      "2/2 - 0s - loss: 0.1668 - accuracy: 0.8125 - 41ms/epoch - 20ms/step\n",
      "Cummulative reward:  40\n",
      "\n",
      ">> Episode:  412 / 800\n",
      "2/2 - 0s - loss: 0.1538 - accuracy: 0.8281 - 47ms/epoch - 24ms/step\n",
      "Cummulative reward:  42\n",
      "\n",
      ">> Episode:  413 / 800\n",
      "2/2 - 0s - loss: 0.1891 - accuracy: 0.7812 - 42ms/epoch - 21ms/step\n",
      "Cummulative reward:  36\n",
      "\n",
      ">> Episode:  414 / 800\n",
      "2/2 - 0s - loss: 0.1374 - accuracy: 0.8750 - 41ms/epoch - 21ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  415 / 800\n",
      "2/2 - 0s - loss: 0.1076 - accuracy: 0.8906 - 39ms/epoch - 20ms/step\n",
      "Cummulative reward:  52\n",
      "\n",
      ">> Episode:  416 / 800\n",
      "2/2 - 0s - loss: 0.1722 - accuracy: 0.8125 - 39ms/epoch - 20ms/step\n",
      "Cummulative reward:  40\n",
      "\n",
      ">> Episode:  417 / 800\n",
      "2/2 - 0s - loss: 0.1320 - accuracy: 0.8594 - 39ms/epoch - 20ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  418 / 800\n",
      "2/2 - 0s - loss: 0.1581 - accuracy: 0.8594 - 39ms/epoch - 19ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  419 / 800\n",
      "2/2 - 0s - loss: 0.1722 - accuracy: 0.8125 - 37ms/epoch - 18ms/step\n",
      "Cummulative reward:  38\n",
      "\n",
      ">> Episode:  420 / 800\n",
      "2/2 - 0s - loss: 0.2098 - accuracy: 0.7812 - 38ms/epoch - 19ms/step\n",
      "Cummulative reward:  32\n",
      "\n",
      ">> Episode:  421 / 800\n",
      "2/2 - 0s - loss: 0.1666 - accuracy: 0.8438 - 38ms/epoch - 19ms/step\n",
      "Cummulative reward:  42\n",
      "\n",
      ">> Episode:  422 / 800\n",
      "2/2 - 0s - loss: 0.1642 - accuracy: 0.8438 - 38ms/epoch - 19ms/step\n",
      "Cummulative reward:  42\n",
      "\n",
      ">> Episode:  423 / 800\n",
      "2/2 - 0s - loss: 0.1606 - accuracy: 0.8281 - 45ms/epoch - 22ms/step\n",
      "Cummulative reward:  42\n",
      "\n",
      ">> Episode:  424 / 800\n",
      "2/2 - 0s - loss: 0.1581 - accuracy: 0.8281 - 38ms/epoch - 19ms/step\n",
      "Cummulative reward:  42\n",
      "\n",
      ">> Episode:  425 / 800\n",
      "2/2 - 0s - loss: 0.1754 - accuracy: 0.8281 - 49ms/epoch - 25ms/step\n",
      "Cummulative reward:  42\n",
      "\n",
      ">> Episode:  426 / 800\n",
      "2/2 - 0s - loss: 0.1304 - accuracy: 0.8438 - 49ms/epoch - 24ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  427 / 800\n",
      "2/2 - 0s - loss: 0.1346 - accuracy: 0.8594 - 59ms/epoch - 30ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  428 / 800\n",
      "2/2 - 0s - loss: 0.1437 - accuracy: 0.8594 - 48ms/epoch - 24ms/step\n",
      "Cummulative reward:  48\n",
      "\n",
      ">> Episode:  429 / 800\n",
      "2/2 - 0s - loss: 0.1487 - accuracy: 0.8281 - 57ms/epoch - 29ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  430 / 800\n",
      "2/2 - 0s - loss: 0.1923 - accuracy: 0.7969 - 64ms/epoch - 32ms/step\n",
      "Cummulative reward:  38\n",
      "\n",
      ">> Episode:  431 / 800\n",
      "2/2 - 0s - loss: 0.2313 - accuracy: 0.7188 - 43ms/epoch - 22ms/step\n",
      "Cummulative reward:  28\n",
      "\n",
      ">> Episode:  432 / 800\n",
      "2/2 - 0s - loss: 0.1771 - accuracy: 0.8125 - 51ms/epoch - 26ms/step\n",
      "Cummulative reward:  38\n",
      "\n",
      ">> Episode:  433 / 800\n",
      "2/2 - 0s - loss: 0.1573 - accuracy: 0.8438 - 40ms/epoch - 20ms/step\n",
      "Cummulative reward:  42\n",
      "\n",
      ">> Episode:  434 / 800\n",
      "2/2 - 0s - loss: 0.1747 - accuracy: 0.7969 - 42ms/epoch - 21ms/step\n",
      "Cummulative reward:  40\n",
      "\n",
      ">> Episode:  435 / 800\n",
      "2/2 - 0s - loss: 0.1955 - accuracy: 0.7656 - 39ms/epoch - 19ms/step\n",
      "Cummulative reward:  34\n",
      "\n",
      ">> Episode:  436 / 800\n",
      "2/2 - 0s - loss: 0.1453 - accuracy: 0.8438 - 38ms/epoch - 19ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  437 / 800\n",
      "2/2 - 0s - loss: 0.1275 - accuracy: 0.8750 - 39ms/epoch - 20ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  438 / 800\n",
      "2/2 - 0s - loss: 0.1034 - accuracy: 0.9062 - 38ms/epoch - 19ms/step\n",
      "Cummulative reward:  54\n",
      "\n",
      ">> Episode:  439 / 800\n",
      "2/2 - 0s - loss: 0.1336 - accuracy: 0.8906 - 43ms/epoch - 22ms/step\n",
      "Cummulative reward:  48\n",
      "\n",
      ">> Episode:  440 / 800\n",
      "2/2 - 0s - loss: 0.1695 - accuracy: 0.8281 - 43ms/epoch - 21ms/step\n",
      "Cummulative reward:  42\n",
      "\n",
      ">> Episode:  441 / 800\n",
      "2/2 - 0s - loss: 0.1877 - accuracy: 0.7969 - 62ms/epoch - 31ms/step\n",
      "Cummulative reward:  38\n",
      "\n",
      ">> Episode:  442 / 800\n",
      "2/2 - 0s - loss: 0.1875 - accuracy: 0.7969 - 40ms/epoch - 20ms/step\n",
      "Cummulative reward:  34\n",
      "\n",
      ">> Episode:  443 / 800\n",
      "2/2 - 0s - loss: 0.1494 - accuracy: 0.8594 - 73ms/epoch - 36ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  444 / 800\n",
      "2/2 - 0s - loss: 0.1611 - accuracy: 0.8281 - 47ms/epoch - 23ms/step\n",
      "Cummulative reward:  42\n",
      "\n",
      ">> Episode:  445 / 800\n",
      "2/2 - 0s - loss: 0.1556 - accuracy: 0.7969 - 53ms/epoch - 26ms/step\n",
      "Cummulative reward:  40\n",
      "\n",
      ">> Episode:  446 / 800\n",
      "2/2 - 0s - loss: 0.1798 - accuracy: 0.7969 - 44ms/epoch - 22ms/step\n",
      "Cummulative reward:  38\n",
      "\n",
      ">> Episode:  447 / 800\n",
      "2/2 - 0s - loss: 0.1635 - accuracy: 0.8281 - 50ms/epoch - 25ms/step\n",
      "Cummulative reward:  38\n",
      "\n",
      ">> Episode:  448 / 800\n",
      "2/2 - 0s - loss: 0.1642 - accuracy: 0.8438 - 46ms/epoch - 23ms/step\n",
      "Cummulative reward:  40\n",
      "\n",
      ">> Episode:  449 / 800\n",
      "2/2 - 0s - loss: 0.2012 - accuracy: 0.7812 - 40ms/epoch - 20ms/step\n",
      "Cummulative reward:  34\n",
      "\n",
      ">> Episode:  450 / 800\n",
      "2/2 - 0s - loss: 0.1560 - accuracy: 0.8281 - 41ms/epoch - 21ms/step\n",
      "Cummulative reward:  42\n",
      "\n",
      ">> Episode:  451 / 800\n",
      "2/2 - 0s - loss: 0.1486 - accuracy: 0.8281 - 40ms/epoch - 20ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  452 / 800\n",
      "2/2 - 0s - loss: 0.1382 - accuracy: 0.8594 - 46ms/epoch - 23ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  453 / 800\n",
      "2/2 - 0s - loss: 0.2222 - accuracy: 0.7656 - 44ms/epoch - 22ms/step\n",
      "Cummulative reward:  28\n",
      "\n",
      ">> Episode:  454 / 800\n",
      "2/2 - 0s - loss: 0.2250 - accuracy: 0.7344 - 39ms/epoch - 20ms/step\n",
      "Cummulative reward:  32\n",
      "\n",
      ">> Episode:  455 / 800\n",
      "2/2 - 0s - loss: 0.1793 - accuracy: 0.8125 - 40ms/epoch - 20ms/step\n",
      "Cummulative reward:  40\n",
      "\n",
      ">> Episode:  456 / 800\n",
      "2/2 - 0s - loss: 0.1548 - accuracy: 0.8438 - 41ms/epoch - 20ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  457 / 800\n",
      "2/2 - 0s - loss: 0.1879 - accuracy: 0.7969 - 62ms/epoch - 31ms/step\n",
      "Cummulative reward:  36\n",
      "\n",
      ">> Episode:  458 / 800\n",
      "2/2 - 0s - loss: 0.1648 - accuracy: 0.8125 - 39ms/epoch - 20ms/step\n",
      "Cummulative reward:  38\n",
      "\n",
      ">> Episode:  459 / 800\n",
      "2/2 - 0s - loss: 0.1632 - accuracy: 0.8281 - 41ms/epoch - 20ms/step\n",
      "Cummulative reward:  42\n",
      "\n",
      ">> Episode:  460 / 800\n",
      "2/2 - 0s - loss: 0.1218 - accuracy: 0.8906 - 40ms/epoch - 20ms/step\n",
      "Cummulative reward:  48\n",
      "\n",
      ">> Episode:  461 / 800\n",
      "2/2 - 0s - loss: 0.1309 - accuracy: 0.8750 - 40ms/epoch - 20ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  462 / 800\n",
      "2/2 - 0s - loss: 0.2165 - accuracy: 0.7656 - 40ms/epoch - 20ms/step\n",
      "Cummulative reward:  34\n",
      "\n",
      ">> Episode:  463 / 800\n",
      "2/2 - 0s - loss: 0.1852 - accuracy: 0.8125 - 40ms/epoch - 20ms/step\n",
      "Cummulative reward:  40\n",
      "\n",
      ">> Episode:  464 / 800\n",
      "2/2 - 0s - loss: 0.1141 - accuracy: 0.9062 - 40ms/epoch - 20ms/step\n",
      "Cummulative reward:  50\n",
      "\n",
      ">> Episode:  465 / 800\n",
      "2/2 - 0s - loss: 0.1522 - accuracy: 0.8281 - 40ms/epoch - 20ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  466 / 800\n",
      "2/2 - 0s - loss: 0.1430 - accuracy: 0.8750 - 41ms/epoch - 20ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  467 / 800\n",
      "2/2 - 0s - loss: 0.2200 - accuracy: 0.7656 - 40ms/epoch - 20ms/step\n",
      "Cummulative reward:  34\n",
      "\n",
      ">> Episode:  468 / 800\n",
      "2/2 - 0s - loss: 0.1409 - accuracy: 0.8594 - 39ms/epoch - 20ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  469 / 800\n",
      "2/2 - 0s - loss: 0.1694 - accuracy: 0.8281 - 42ms/epoch - 21ms/step\n",
      "Cummulative reward:  42\n",
      "\n",
      ">> Episode:  470 / 800\n",
      "2/2 - 0s - loss: 0.1189 - accuracy: 0.8906 - 39ms/epoch - 20ms/step\n",
      "Cummulative reward:  50\n",
      "\n",
      ">> Episode:  471 / 800\n",
      "2/2 - 0s - loss: 0.1283 - accuracy: 0.8750 - 40ms/epoch - 20ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  472 / 800\n",
      "2/2 - 0s - loss: 0.1644 - accuracy: 0.8438 - 52ms/epoch - 26ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  473 / 800\n",
      "2/2 - 0s - loss: 0.1137 - accuracy: 0.9062 - 44ms/epoch - 22ms/step\n",
      "Cummulative reward:  52\n",
      "\n",
      ">> Episode:  474 / 800\n",
      "2/2 - 0s - loss: 0.2659 - accuracy: 0.7188 - 42ms/epoch - 21ms/step\n",
      "Cummulative reward:  26\n",
      "\n",
      ">> Episode:  475 / 800\n",
      "2/2 - 0s - loss: 0.1237 - accuracy: 0.8906 - 40ms/epoch - 20ms/step\n",
      "Cummulative reward:  50\n",
      "\n",
      ">> Episode:  476 / 800\n",
      "2/2 - 0s - loss: 0.1194 - accuracy: 0.8750 - 41ms/epoch - 21ms/step\n",
      "Cummulative reward:  48\n",
      "\n",
      ">> Episode:  477 / 800\n",
      "2/2 - 0s - loss: 0.1792 - accuracy: 0.8125 - 42ms/epoch - 21ms/step\n",
      "Cummulative reward:  40\n",
      "\n",
      ">> Episode:  478 / 800\n",
      "2/2 - 0s - loss: 0.1637 - accuracy: 0.8438 - 42ms/epoch - 21ms/step\n",
      "Cummulative reward:  40\n",
      "\n",
      ">> Episode:  479 / 800\n",
      "2/2 - 0s - loss: 0.1456 - accuracy: 0.8750 - 42ms/epoch - 21ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  480 / 800\n",
      "2/2 - 0s - loss: 0.1395 - accuracy: 0.8438 - 43ms/epoch - 22ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  481 / 800\n",
      "2/2 - 0s - loss: 0.1958 - accuracy: 0.8125 - 41ms/epoch - 21ms/step\n",
      "Cummulative reward:  36\n",
      "\n",
      ">> Episode:  482 / 800\n",
      "2/2 - 0s - loss: 0.1433 - accuracy: 0.8281 - 42ms/epoch - 21ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  483 / 800\n",
      "2/2 - 0s - loss: 0.1484 - accuracy: 0.8125 - 41ms/epoch - 21ms/step\n",
      "Cummulative reward:  42\n",
      "\n",
      ">> Episode:  484 / 800\n",
      "2/2 - 0s - loss: 0.1410 - accuracy: 0.8438 - 43ms/epoch - 22ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  485 / 800\n",
      "2/2 - 0s - loss: 0.1832 - accuracy: 0.8125 - 43ms/epoch - 21ms/step\n",
      "Cummulative reward:  38\n",
      "\n",
      ">> Episode:  486 / 800\n",
      "2/2 - 0s - loss: 0.1244 - accuracy: 0.8594 - 43ms/epoch - 21ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  487 / 800\n",
      "2/2 - 0s - loss: 0.1131 - accuracy: 0.8750 - 44ms/epoch - 22ms/step\n",
      "Cummulative reward:  52\n",
      "\n",
      ">> Episode:  488 / 800\n",
      "2/2 - 0s - loss: 0.1634 - accuracy: 0.8438 - 42ms/epoch - 21ms/step\n",
      "Cummulative reward:  42\n",
      "\n",
      ">> Episode:  489 / 800\n",
      "2/2 - 0s - loss: 0.1400 - accuracy: 0.8594 - 42ms/epoch - 21ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  490 / 800\n",
      "2/2 - 0s - loss: 0.1065 - accuracy: 0.9062 - 44ms/epoch - 22ms/step\n",
      "Cummulative reward:  52\n",
      "\n",
      ">> Episode:  491 / 800\n",
      "2/2 - 0s - loss: 0.1669 - accuracy: 0.8125 - 44ms/epoch - 22ms/step\n",
      "Cummulative reward:  38\n",
      "\n",
      ">> Episode:  492 / 800\n",
      "2/2 - 0s - loss: 0.1034 - accuracy: 0.9062 - 43ms/epoch - 21ms/step\n",
      "Cummulative reward:  52\n",
      "\n",
      ">> Episode:  493 / 800\n",
      "2/2 - 0s - loss: 0.1503 - accuracy: 0.8438 - 43ms/epoch - 21ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  494 / 800\n",
      "2/2 - 0s - loss: 0.1094 - accuracy: 0.8906 - 44ms/epoch - 22ms/step\n",
      "Cummulative reward:  48\n",
      "\n",
      ">> Episode:  495 / 800\n",
      "2/2 - 0s - loss: 0.1813 - accuracy: 0.8125 - 43ms/epoch - 21ms/step\n",
      "Cummulative reward:  38\n",
      "\n",
      ">> Episode:  496 / 800\n",
      "2/2 - 0s - loss: 0.1955 - accuracy: 0.7812 - 43ms/epoch - 21ms/step\n",
      "Cummulative reward:  36\n",
      "\n",
      ">> Episode:  497 / 800\n",
      "2/2 - 0s - loss: 0.0883 - accuracy: 0.9219 - 43ms/epoch - 21ms/step\n",
      "Cummulative reward:  54\n",
      "\n",
      ">> Episode:  498 / 800\n",
      "2/2 - 0s - loss: 0.1745 - accuracy: 0.8125 - 43ms/epoch - 21ms/step\n",
      "Cummulative reward:  38\n",
      "\n",
      ">> Episode:  499 / 800\n",
      "2/2 - 0s - loss: 0.1728 - accuracy: 0.7969 - 64ms/epoch - 32ms/step\n",
      "Cummulative reward:  38\n",
      "\n",
      ">> Episode:  500 / 800\n",
      "2/2 - 0s - loss: 0.1642 - accuracy: 0.8125 - 44ms/epoch - 22ms/step\n",
      "Cummulative reward:  38\n",
      "\n",
      ">> Episode:  501 / 800\n",
      "2/2 - 0s - loss: 0.1254 - accuracy: 0.8594 - 43ms/epoch - 22ms/step\n",
      "Cummulative reward:  48\n",
      "\n",
      ">> Episode:  502 / 800\n",
      "2/2 - 0s - loss: 0.2027 - accuracy: 0.7969 - 60ms/epoch - 30ms/step\n",
      "Cummulative reward:  36\n",
      "\n",
      ">> Episode:  503 / 800\n",
      "2/2 - 0s - loss: 0.1551 - accuracy: 0.8125 - 44ms/epoch - 22ms/step\n",
      "Cummulative reward:  40\n",
      "\n",
      ">> Episode:  504 / 800\n",
      "2/2 - 0s - loss: 0.1267 - accuracy: 0.8750 - 44ms/epoch - 22ms/step\n",
      "Cummulative reward:  48\n",
      "\n",
      ">> Episode:  505 / 800\n",
      "2/2 - 0s - loss: 0.1701 - accuracy: 0.8438 - 44ms/epoch - 22ms/step\n",
      "Cummulative reward:  40\n",
      "\n",
      ">> Episode:  506 / 800\n",
      "2/2 - 0s - loss: 0.1708 - accuracy: 0.8281 - 53ms/epoch - 26ms/step\n",
      "Cummulative reward:  38\n",
      "\n",
      ">> Episode:  507 / 800\n",
      "2/2 - 0s - loss: 0.1367 - accuracy: 0.8438 - 45ms/epoch - 22ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  508 / 800\n",
      "2/2 - 0s - loss: 0.1143 - accuracy: 0.8906 - 43ms/epoch - 22ms/step\n",
      "Cummulative reward:  50\n",
      "\n",
      ">> Episode:  509 / 800\n",
      "2/2 - 0s - loss: 0.1074 - accuracy: 0.9062 - 52ms/epoch - 26ms/step\n",
      "Cummulative reward:  52\n",
      "\n",
      ">> Episode:  510 / 800\n",
      "2/2 - 0s - loss: 0.1345 - accuracy: 0.8906 - 43ms/epoch - 21ms/step\n",
      "Cummulative reward:  48\n",
      "\n",
      ">> Episode:  511 / 800\n",
      "2/2 - 0s - loss: 0.1125 - accuracy: 0.8750 - 43ms/epoch - 22ms/step\n",
      "Cummulative reward:  50\n",
      "\n",
      ">> Episode:  512 / 800\n",
      "2/2 - 0s - loss: 0.1126 - accuracy: 0.8750 - 43ms/epoch - 22ms/step\n",
      "Cummulative reward:  48\n",
      "\n",
      ">> Episode:  513 / 800\n",
      "2/2 - 0s - loss: 0.1092 - accuracy: 0.8594 - 43ms/epoch - 22ms/step\n",
      "Cummulative reward:  48\n",
      "\n",
      ">> Episode:  514 / 800\n",
      "2/2 - 0s - loss: 0.1865 - accuracy: 0.7969 - 47ms/epoch - 23ms/step\n",
      "Cummulative reward:  34\n",
      "\n",
      ">> Episode:  515 / 800\n",
      "2/2 - 0s - loss: 0.0946 - accuracy: 0.9219 - 60ms/epoch - 30ms/step\n",
      "Cummulative reward:  52\n",
      "\n",
      ">> Episode:  516 / 800\n",
      "2/2 - 0s - loss: 0.1058 - accuracy: 0.9062 - 59ms/epoch - 29ms/step\n",
      "Cummulative reward:  52\n",
      "\n",
      ">> Episode:  517 / 800\n",
      "2/2 - 0s - loss: 0.1102 - accuracy: 0.8906 - 60ms/epoch - 30ms/step\n",
      "Cummulative reward:  50\n",
      "\n",
      ">> Episode:  518 / 800\n",
      "2/2 - 0s - loss: 0.1104 - accuracy: 0.9062 - 58ms/epoch - 29ms/step\n",
      "Cummulative reward:  48\n",
      "\n",
      ">> Episode:  519 / 800\n",
      "2/2 - 0s - loss: 0.1458 - accuracy: 0.8281 - 58ms/epoch - 29ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  520 / 800\n",
      "2/2 - 0s - loss: 0.1476 - accuracy: 0.8438 - 47ms/epoch - 23ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  521 / 800\n",
      "2/2 - 0s - loss: 0.1614 - accuracy: 0.8438 - 45ms/epoch - 22ms/step\n",
      "Cummulative reward:  40\n",
      "\n",
      ">> Episode:  522 / 800\n",
      "2/2 - 0s - loss: 0.1384 - accuracy: 0.8594 - 44ms/epoch - 22ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  523 / 800\n",
      "2/2 - 0s - loss: 0.1042 - accuracy: 0.9219 - 44ms/epoch - 22ms/step\n",
      "Cummulative reward:  50\n",
      "\n",
      ">> Episode:  524 / 800\n",
      "2/2 - 0s - loss: 0.1733 - accuracy: 0.7812 - 44ms/epoch - 22ms/step\n",
      "Cummulative reward:  38\n",
      "\n",
      ">> Episode:  525 / 800\n",
      "2/2 - 0s - loss: 0.1276 - accuracy: 0.8438 - 59ms/epoch - 30ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  526 / 800\n",
      "2/2 - 0s - loss: 0.1730 - accuracy: 0.7969 - 45ms/epoch - 22ms/step\n",
      "Cummulative reward:  40\n",
      "\n",
      ">> Episode:  527 / 800\n",
      "2/2 - 0s - loss: 0.1665 - accuracy: 0.8281 - 45ms/epoch - 23ms/step\n",
      "Cummulative reward:  40\n",
      "\n",
      ">> Episode:  528 / 800\n",
      "2/2 - 0s - loss: 0.1137 - accuracy: 0.8750 - 44ms/epoch - 22ms/step\n",
      "Cummulative reward:  48\n",
      "\n",
      ">> Episode:  529 / 800\n",
      "2/2 - 0s - loss: 0.2265 - accuracy: 0.7344 - 44ms/epoch - 22ms/step\n",
      "Cummulative reward:  30\n",
      "\n",
      ">> Episode:  530 / 800\n",
      "2/2 - 0s - loss: 0.1246 - accuracy: 0.8906 - 44ms/epoch - 22ms/step\n",
      "Cummulative reward:  50\n",
      "\n",
      ">> Episode:  531 / 800\n",
      "2/2 - 0s - loss: 0.1678 - accuracy: 0.8281 - 46ms/epoch - 23ms/step\n",
      "Cummulative reward:  42\n",
      "\n",
      ">> Episode:  532 / 800\n",
      "2/2 - 0s - loss: 0.1713 - accuracy: 0.8125 - 46ms/epoch - 23ms/step\n",
      "Cummulative reward:  38\n",
      "\n",
      ">> Episode:  533 / 800\n",
      "2/2 - 0s - loss: 0.0876 - accuracy: 0.9375 - 43ms/epoch - 21ms/step\n",
      "Cummulative reward:  54\n",
      "\n",
      ">> Episode:  534 / 800\n",
      "2/2 - 0s - loss: 0.1434 - accuracy: 0.8438 - 44ms/epoch - 22ms/step\n",
      "Cummulative reward:  48\n",
      "\n",
      ">> Episode:  535 / 800\n",
      "2/2 - 0s - loss: 0.1912 - accuracy: 0.7812 - 46ms/epoch - 23ms/step\n",
      "Cummulative reward:  38\n",
      "\n",
      ">> Episode:  536 / 800\n",
      "2/2 - 0s - loss: 0.1508 - accuracy: 0.8438 - 45ms/epoch - 22ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  537 / 800\n",
      "2/2 - 0s - loss: 0.2321 - accuracy: 0.7500 - 45ms/epoch - 23ms/step\n",
      "Cummulative reward:  34\n",
      "\n",
      ">> Episode:  538 / 800\n",
      "2/2 - 0s - loss: 0.2160 - accuracy: 0.7656 - 47ms/epoch - 23ms/step\n",
      "Cummulative reward:  30\n",
      "\n",
      ">> Episode:  539 / 800\n",
      "2/2 - 0s - loss: 0.1775 - accuracy: 0.7969 - 46ms/epoch - 23ms/step\n",
      "Cummulative reward:  38\n",
      "\n",
      ">> Episode:  540 / 800\n",
      "2/2 - 0s - loss: 0.1329 - accuracy: 0.8438 - 45ms/epoch - 23ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  541 / 800\n",
      "2/2 - 0s - loss: 0.1710 - accuracy: 0.8281 - 46ms/epoch - 23ms/step\n",
      "Cummulative reward:  42\n",
      "\n",
      ">> Episode:  542 / 800\n",
      "2/2 - 0s - loss: 0.1917 - accuracy: 0.7969 - 48ms/epoch - 24ms/step\n",
      "Cummulative reward:  40\n",
      "\n",
      ">> Episode:  543 / 800\n",
      "2/2 - 0s - loss: 0.1179 - accuracy: 0.8750 - 45ms/epoch - 22ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  544 / 800\n",
      "2/2 - 0s - loss: 0.1565 - accuracy: 0.8281 - 45ms/epoch - 23ms/step\n",
      "Cummulative reward:  42\n",
      "\n",
      ">> Episode:  545 / 800\n",
      "2/2 - 0s - loss: 0.1768 - accuracy: 0.8281 - 45ms/epoch - 23ms/step\n",
      "Cummulative reward:  42\n",
      "\n",
      ">> Episode:  546 / 800\n",
      "2/2 - 0s - loss: 0.1104 - accuracy: 0.9062 - 47ms/epoch - 24ms/step\n",
      "Cummulative reward:  50\n",
      "\n",
      ">> Episode:  547 / 800\n",
      "2/2 - 0s - loss: 0.1564 - accuracy: 0.8594 - 46ms/epoch - 23ms/step\n",
      "Cummulative reward:  42\n",
      "\n",
      ">> Episode:  548 / 800\n",
      "2/2 - 0s - loss: 0.1505 - accuracy: 0.8594 - 46ms/epoch - 23ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  549 / 800\n",
      "2/2 - 0s - loss: 0.2080 - accuracy: 0.7656 - 46ms/epoch - 23ms/step\n",
      "Cummulative reward:  32\n",
      "\n",
      ">> Episode:  550 / 800\n",
      "2/2 - 0s - loss: 0.1019 - accuracy: 0.9062 - 45ms/epoch - 22ms/step\n",
      "Cummulative reward:  52\n",
      "\n",
      ">> Episode:  551 / 800\n",
      "2/2 - 0s - loss: 0.1312 - accuracy: 0.8594 - 47ms/epoch - 24ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  552 / 800\n",
      "2/2 - 0s - loss: 0.1196 - accuracy: 0.8906 - 47ms/epoch - 23ms/step\n",
      "Cummulative reward:  50\n",
      "\n",
      ">> Episode:  553 / 800\n",
      "2/2 - 0s - loss: 0.1092 - accuracy: 0.9062 - 47ms/epoch - 23ms/step\n",
      "Cummulative reward:  50\n",
      "\n",
      ">> Episode:  554 / 800\n",
      "2/2 - 0s - loss: 0.1009 - accuracy: 0.9062 - 46ms/epoch - 23ms/step\n",
      "Cummulative reward:  52\n",
      "\n",
      ">> Episode:  555 / 800\n",
      "2/2 - 0s - loss: 0.1275 - accuracy: 0.8594 - 47ms/epoch - 23ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  556 / 800\n",
      "2/2 - 0s - loss: 0.1813 - accuracy: 0.8125 - 48ms/epoch - 24ms/step\n",
      "Cummulative reward:  40\n",
      "\n",
      ">> Episode:  557 / 800\n",
      "2/2 - 0s - loss: 0.2576 - accuracy: 0.7500 - 47ms/epoch - 24ms/step\n",
      "Cummulative reward:  28\n",
      "\n",
      ">> Episode:  558 / 800\n",
      "2/2 - 0s - loss: 0.2057 - accuracy: 0.7969 - 45ms/epoch - 23ms/step\n",
      "Cummulative reward:  38\n",
      "\n",
      ">> Episode:  559 / 800\n",
      "2/2 - 0s - loss: 0.1350 - accuracy: 0.8750 - 48ms/epoch - 24ms/step\n",
      "Cummulative reward:  48\n",
      "\n",
      ">> Episode:  560 / 800\n",
      "2/2 - 0s - loss: 0.1928 - accuracy: 0.7656 - 45ms/epoch - 22ms/step\n",
      "Cummulative reward:  36\n",
      "\n",
      ">> Episode:  561 / 800\n",
      "2/2 - 0s - loss: 0.1944 - accuracy: 0.8125 - 50ms/epoch - 25ms/step\n",
      "Cummulative reward:  40\n",
      "\n",
      ">> Episode:  562 / 800\n",
      "2/2 - 0s - loss: 0.1559 - accuracy: 0.8438 - 45ms/epoch - 23ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  563 / 800\n",
      "2/2 - 0s - loss: 0.1758 - accuracy: 0.7969 - 48ms/epoch - 24ms/step\n",
      "Cummulative reward:  38\n",
      "\n",
      ">> Episode:  564 / 800\n",
      "2/2 - 0s - loss: 0.1359 - accuracy: 0.8594 - 48ms/epoch - 24ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  565 / 800\n",
      "2/2 - 0s - loss: 0.1576 - accuracy: 0.8594 - 49ms/epoch - 25ms/step\n",
      "Cummulative reward:  42\n",
      "\n",
      ">> Episode:  566 / 800\n",
      "2/2 - 0s - loss: 0.1979 - accuracy: 0.7969 - 50ms/epoch - 25ms/step\n",
      "Cummulative reward:  36\n",
      "\n",
      ">> Episode:  567 / 800\n",
      "2/2 - 0s - loss: 0.0874 - accuracy: 0.9219 - 46ms/epoch - 23ms/step\n",
      "Cummulative reward:  54\n",
      "\n",
      ">> Episode:  568 / 800\n",
      "2/2 - 0s - loss: 0.0988 - accuracy: 0.9062 - 47ms/epoch - 23ms/step\n",
      "Cummulative reward:  52\n",
      "\n",
      ">> Episode:  569 / 800\n",
      "2/2 - 0s - loss: 0.0746 - accuracy: 0.9375 - 65ms/epoch - 33ms/step\n",
      "Cummulative reward:  56\n",
      "\n",
      ">> Episode:  570 / 800\n",
      "2/2 - 0s - loss: 0.2405 - accuracy: 0.7344 - 48ms/epoch - 24ms/step\n",
      "Cummulative reward:  30\n",
      "\n",
      ">> Episode:  571 / 800\n",
      "2/2 - 0s - loss: 0.1514 - accuracy: 0.8438 - 47ms/epoch - 23ms/step\n",
      "Cummulative reward:  40\n",
      "\n",
      ">> Episode:  572 / 800\n",
      "2/2 - 0s - loss: 0.2310 - accuracy: 0.7344 - 48ms/epoch - 24ms/step\n",
      "Cummulative reward:  30\n",
      "\n",
      ">> Episode:  573 / 800\n",
      "2/2 - 0s - loss: 0.1728 - accuracy: 0.8438 - 49ms/epoch - 25ms/step\n",
      "Cummulative reward:  40\n",
      "\n",
      ">> Episode:  574 / 800\n",
      "2/2 - 0s - loss: 0.1228 - accuracy: 0.8906 - 59ms/epoch - 29ms/step\n",
      "Cummulative reward:  50\n",
      "\n",
      ">> Episode:  575 / 800\n",
      "2/2 - 0s - loss: 0.1224 - accuracy: 0.8750 - 77ms/epoch - 38ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  576 / 800\n",
      "2/2 - 0s - loss: 0.1601 - accuracy: 0.8281 - 52ms/epoch - 26ms/step\n",
      "Cummulative reward:  40\n",
      "\n",
      ">> Episode:  577 / 800\n",
      "2/2 - 0s - loss: 0.1046 - accuracy: 0.8906 - 48ms/epoch - 24ms/step\n",
      "Cummulative reward:  50\n",
      "\n",
      ">> Episode:  578 / 800\n",
      "2/2 - 0s - loss: 0.1748 - accuracy: 0.8125 - 46ms/epoch - 23ms/step\n",
      "Cummulative reward:  40\n",
      "\n",
      ">> Episode:  579 / 800\n",
      "2/2 - 0s - loss: 0.1599 - accuracy: 0.8125 - 48ms/epoch - 24ms/step\n",
      "Cummulative reward:  42\n",
      "\n",
      ">> Episode:  580 / 800\n",
      "2/2 - 0s - loss: 0.1194 - accuracy: 0.8906 - 48ms/epoch - 24ms/step\n",
      "Cummulative reward:  50\n",
      "\n",
      ">> Episode:  581 / 800\n",
      "2/2 - 0s - loss: 0.1239 - accuracy: 0.8750 - 45ms/epoch - 23ms/step\n",
      "Cummulative reward:  48\n",
      "\n",
      ">> Episode:  582 / 800\n",
      "2/2 - 0s - loss: 0.1134 - accuracy: 0.8906 - 60ms/epoch - 30ms/step\n",
      "Cummulative reward:  50\n",
      "\n",
      ">> Episode:  583 / 800\n",
      "2/2 - 0s - loss: 0.1230 - accuracy: 0.8750 - 48ms/epoch - 24ms/step\n",
      "Cummulative reward:  48\n",
      "\n",
      ">> Episode:  584 / 800\n",
      "2/2 - 0s - loss: 0.1296 - accuracy: 0.8750 - 47ms/epoch - 24ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  585 / 800\n",
      "2/2 - 0s - loss: 0.1576 - accuracy: 0.8125 - 53ms/epoch - 26ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  586 / 800\n",
      "2/2 - 0s - loss: 0.1339 - accuracy: 0.8594 - 48ms/epoch - 24ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  587 / 800\n",
      "2/2 - 0s - loss: 0.1235 - accuracy: 0.8750 - 47ms/epoch - 24ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  588 / 800\n",
      "2/2 - 0s - loss: 0.1525 - accuracy: 0.8438 - 57ms/epoch - 28ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  589 / 800\n",
      "2/2 - 0s - loss: 0.1243 - accuracy: 0.8750 - 46ms/epoch - 23ms/step\n",
      "Cummulative reward:  48\n",
      "\n",
      ">> Episode:  590 / 800\n",
      "2/2 - 0s - loss: 0.1034 - accuracy: 0.8906 - 47ms/epoch - 24ms/step\n",
      "Cummulative reward:  50\n",
      "\n",
      ">> Episode:  591 / 800\n",
      "2/2 - 0s - loss: 0.1430 - accuracy: 0.8438 - 49ms/epoch - 24ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  592 / 800\n",
      "2/2 - 0s - loss: 0.1887 - accuracy: 0.7656 - 55ms/epoch - 27ms/step\n",
      "Cummulative reward:  36\n",
      "\n",
      ">> Episode:  593 / 800\n",
      "2/2 - 0s - loss: 0.1545 - accuracy: 0.8438 - 49ms/epoch - 24ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  594 / 800\n",
      "2/2 - 0s - loss: 0.1525 - accuracy: 0.8438 - 52ms/epoch - 26ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  595 / 800\n",
      "2/2 - 0s - loss: 0.1633 - accuracy: 0.8594 - 61ms/epoch - 30ms/step\n",
      "Cummulative reward:  42\n",
      "\n",
      ">> Episode:  596 / 800\n",
      "2/2 - 0s - loss: 0.1457 - accuracy: 0.8594 - 51ms/epoch - 26ms/step\n",
      "Cummulative reward:  42\n",
      "\n",
      ">> Episode:  597 / 800\n",
      "2/2 - 0s - loss: 0.1428 - accuracy: 0.8594 - 49ms/epoch - 25ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  598 / 800\n",
      "2/2 - 0s - loss: 0.1110 - accuracy: 0.9062 - 51ms/epoch - 25ms/step\n",
      "Cummulative reward:  50\n",
      "\n",
      ">> Episode:  599 / 800\n",
      "2/2 - 0s - loss: 0.1114 - accuracy: 0.8750 - 50ms/epoch - 25ms/step\n",
      "Cummulative reward:  50\n",
      "\n",
      ">> Episode:  600 / 800\n",
      "2/2 - 0s - loss: 0.1164 - accuracy: 0.8906 - 51ms/epoch - 25ms/step\n",
      "Cummulative reward:  50\n",
      "\n",
      ">> Episode:  601 / 800\n",
      "2/2 - 0s - loss: 0.1573 - accuracy: 0.7969 - 52ms/epoch - 26ms/step\n",
      "Cummulative reward:  40\n",
      "\n",
      ">> Episode:  602 / 800\n",
      "2/2 - 0s - loss: 0.2250 - accuracy: 0.7344 - 51ms/epoch - 25ms/step\n",
      "Cummulative reward:  30\n",
      "\n",
      ">> Episode:  603 / 800\n",
      "2/2 - 0s - loss: 0.1636 - accuracy: 0.7969 - 51ms/epoch - 25ms/step\n",
      "Cummulative reward:  40\n",
      "\n",
      ">> Episode:  604 / 800\n",
      "2/2 - 0s - loss: 0.1098 - accuracy: 0.8750 - 54ms/epoch - 27ms/step\n",
      "Cummulative reward:  50\n",
      "\n",
      ">> Episode:  605 / 800\n",
      "2/2 - 0s - loss: 0.1987 - accuracy: 0.7812 - 54ms/epoch - 27ms/step\n",
      "Cummulative reward:  34\n",
      "\n",
      ">> Episode:  606 / 800\n",
      "2/2 - 0s - loss: 0.1971 - accuracy: 0.7812 - 56ms/epoch - 28ms/step\n",
      "Cummulative reward:  34\n",
      "\n",
      ">> Episode:  607 / 800\n",
      "2/2 - 0s - loss: 0.1746 - accuracy: 0.8125 - 51ms/epoch - 25ms/step\n",
      "Cummulative reward:  38\n",
      "\n",
      ">> Episode:  608 / 800\n",
      "2/2 - 0s - loss: 0.1527 - accuracy: 0.8438 - 81ms/epoch - 40ms/step\n",
      "Cummulative reward:  42\n",
      "\n",
      ">> Episode:  609 / 800\n",
      "2/2 - 0s - loss: 0.0878 - accuracy: 0.9062 - 50ms/epoch - 25ms/step\n",
      "Cummulative reward:  54\n",
      "\n",
      ">> Episode:  610 / 800\n",
      "2/2 - 0s - loss: 0.1251 - accuracy: 0.8438 - 53ms/epoch - 26ms/step\n",
      "Cummulative reward:  48\n",
      "\n",
      ">> Episode:  611 / 800\n",
      "2/2 - 0s - loss: 0.1277 - accuracy: 0.8750 - 56ms/epoch - 28ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  612 / 800\n",
      "2/2 - 0s - loss: 0.1234 - accuracy: 0.8906 - 57ms/epoch - 29ms/step\n",
      "Cummulative reward:  48\n",
      "\n",
      ">> Episode:  613 / 800\n",
      "2/2 - 0s - loss: 0.0709 - accuracy: 0.9531 - 56ms/epoch - 28ms/step\n",
      "Cummulative reward:  58\n",
      "\n",
      ">> Episode:  614 / 800\n",
      "2/2 - 0s - loss: 0.0789 - accuracy: 0.9375 - 57ms/epoch - 28ms/step\n",
      "Cummulative reward:  54\n",
      "\n",
      ">> Episode:  615 / 800\n",
      "2/2 - 0s - loss: 0.0942 - accuracy: 0.9062 - 58ms/epoch - 29ms/step\n",
      "Cummulative reward:  54\n",
      "\n",
      ">> Episode:  616 / 800\n",
      "2/2 - 0s - loss: 0.1826 - accuracy: 0.7812 - 52ms/epoch - 26ms/step\n",
      "Cummulative reward:  36\n",
      "\n",
      ">> Episode:  617 / 800\n",
      "2/2 - 0s - loss: 0.2217 - accuracy: 0.7656 - 52ms/epoch - 26ms/step\n",
      "Cummulative reward:  34\n",
      "\n",
      ">> Episode:  618 / 800\n",
      "2/2 - 0s - loss: 0.1672 - accuracy: 0.8438 - 53ms/epoch - 27ms/step\n",
      "Cummulative reward:  40\n",
      "\n",
      ">> Episode:  619 / 800\n",
      "2/2 - 0s - loss: 0.1539 - accuracy: 0.8438 - 55ms/epoch - 27ms/step\n",
      "Cummulative reward:  42\n",
      "\n",
      ">> Episode:  620 / 800\n",
      "2/2 - 0s - loss: 0.1766 - accuracy: 0.8281 - 55ms/epoch - 27ms/step\n",
      "Cummulative reward:  38\n",
      "\n",
      ">> Episode:  621 / 800\n",
      "2/2 - 0s - loss: 0.1265 - accuracy: 0.8906 - 53ms/epoch - 26ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  622 / 800\n",
      "2/2 - 0s - loss: 0.1823 - accuracy: 0.8125 - 55ms/epoch - 27ms/step\n",
      "Cummulative reward:  40\n",
      "\n",
      ">> Episode:  623 / 800\n",
      "2/2 - 0s - loss: 0.1703 - accuracy: 0.7969 - 54ms/epoch - 27ms/step\n",
      "Cummulative reward:  40\n",
      "\n",
      ">> Episode:  624 / 800\n",
      "2/2 - 0s - loss: 0.1910 - accuracy: 0.8438 - 53ms/epoch - 26ms/step\n",
      "Cummulative reward:  38\n",
      "\n",
      ">> Episode:  625 / 800\n",
      "2/2 - 0s - loss: 0.1334 - accuracy: 0.8594 - 53ms/epoch - 27ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  626 / 800\n",
      "2/2 - 0s - loss: 0.1685 - accuracy: 0.8125 - 57ms/epoch - 28ms/step\n",
      "Cummulative reward:  40\n",
      "\n",
      ">> Episode:  627 / 800\n",
      "2/2 - 0s - loss: 0.1624 - accuracy: 0.8125 - 58ms/epoch - 29ms/step\n",
      "Cummulative reward:  38\n",
      "\n",
      ">> Episode:  628 / 800\n",
      "2/2 - 0s - loss: 0.0631 - accuracy: 0.9375 - 55ms/epoch - 27ms/step\n",
      "Cummulative reward:  58\n",
      "\n",
      ">> Episode:  629 / 800\n",
      "2/2 - 0s - loss: 0.1374 - accuracy: 0.8594 - 57ms/epoch - 29ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  630 / 800\n",
      "2/2 - 0s - loss: 0.1300 - accuracy: 0.8594 - 59ms/epoch - 30ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  631 / 800\n",
      "2/2 - 0s - loss: 0.1115 - accuracy: 0.9062 - 58ms/epoch - 29ms/step\n",
      "Cummulative reward:  50\n",
      "\n",
      ">> Episode:  632 / 800\n",
      "2/2 - 0s - loss: 0.1740 - accuracy: 0.7812 - 58ms/epoch - 29ms/step\n",
      "Cummulative reward:  38\n",
      "\n",
      ">> Episode:  633 / 800\n",
      "2/2 - 0s - loss: 0.1697 - accuracy: 0.8125 - 59ms/epoch - 29ms/step\n",
      "Cummulative reward:  38\n",
      "\n",
      ">> Episode:  634 / 800\n",
      "2/2 - 0s - loss: 0.1809 - accuracy: 0.7969 - 56ms/epoch - 28ms/step\n",
      "Cummulative reward:  38\n",
      "\n",
      ">> Episode:  635 / 800\n",
      "2/2 - 0s - loss: 0.1771 - accuracy: 0.7969 - 57ms/epoch - 29ms/step\n",
      "Cummulative reward:  38\n",
      "\n",
      ">> Episode:  636 / 800\n",
      "2/2 - 0s - loss: 0.1817 - accuracy: 0.7969 - 58ms/epoch - 29ms/step\n",
      "Cummulative reward:  40\n",
      "\n",
      ">> Episode:  637 / 800\n",
      "2/2 - 0s - loss: 0.0742 - accuracy: 0.9531 - 57ms/epoch - 29ms/step\n",
      "Cummulative reward:  56\n",
      "\n",
      ">> Episode:  638 / 800\n",
      "2/2 - 0s - loss: 0.1272 - accuracy: 0.8281 - 57ms/epoch - 28ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  639 / 800\n",
      "2/2 - 0s - loss: 0.1367 - accuracy: 0.8594 - 57ms/epoch - 28ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  640 / 800\n",
      "2/2 - 0s - loss: 0.1515 - accuracy: 0.8281 - 57ms/epoch - 29ms/step\n",
      "Cummulative reward:  42\n",
      "\n",
      ">> Episode:  641 / 800\n",
      "2/2 - 0s - loss: 0.1748 - accuracy: 0.8125 - 58ms/epoch - 29ms/step\n",
      "Cummulative reward:  40\n",
      "\n",
      ">> Episode:  642 / 800\n",
      "2/2 - 0s - loss: 0.1517 - accuracy: 0.8594 - 59ms/epoch - 30ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  643 / 800\n",
      "2/2 - 0s - loss: 0.1619 - accuracy: 0.8281 - 76ms/epoch - 38ms/step\n",
      "Cummulative reward:  40\n",
      "\n",
      ">> Episode:  644 / 800\n",
      "2/2 - 0s - loss: 0.1364 - accuracy: 0.8281 - 99ms/epoch - 49ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  645 / 800\n",
      "2/2 - 0s - loss: 0.1292 - accuracy: 0.8906 - 58ms/epoch - 29ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  646 / 800\n",
      "2/2 - 0s - loss: 0.1850 - accuracy: 0.8125 - 57ms/epoch - 29ms/step\n",
      "Cummulative reward:  38\n",
      "\n",
      ">> Episode:  647 / 800\n",
      "2/2 - 0s - loss: 0.1357 - accuracy: 0.8594 - 59ms/epoch - 29ms/step\n",
      "Cummulative reward:  48\n",
      "\n",
      ">> Episode:  648 / 800\n",
      "2/2 - 0s - loss: 0.1815 - accuracy: 0.7969 - 57ms/epoch - 28ms/step\n",
      "Cummulative reward:  36\n",
      "\n",
      ">> Episode:  649 / 800\n",
      "2/2 - 0s - loss: 0.1825 - accuracy: 0.7969 - 59ms/epoch - 30ms/step\n",
      "Cummulative reward:  38\n",
      "\n",
      ">> Episode:  650 / 800\n",
      "2/2 - 0s - loss: 0.1062 - accuracy: 0.9062 - 57ms/epoch - 29ms/step\n",
      "Cummulative reward:  52\n",
      "\n",
      ">> Episode:  651 / 800\n",
      "2/2 - 0s - loss: 0.1729 - accuracy: 0.8281 - 57ms/epoch - 28ms/step\n",
      "Cummulative reward:  38\n",
      "\n",
      ">> Episode:  652 / 800\n",
      "2/2 - 0s - loss: 0.1881 - accuracy: 0.7812 - 58ms/epoch - 29ms/step\n",
      "Cummulative reward:  34\n",
      "\n",
      ">> Episode:  653 / 800\n",
      "2/2 - 0s - loss: 0.2136 - accuracy: 0.7656 - 57ms/epoch - 28ms/step\n",
      "Cummulative reward:  34\n",
      "\n",
      ">> Episode:  654 / 800\n",
      "2/2 - 0s - loss: 0.1751 - accuracy: 0.8125 - 57ms/epoch - 29ms/step\n",
      "Cummulative reward:  40\n",
      "\n",
      ">> Episode:  655 / 800\n",
      "2/2 - 0s - loss: 0.0889 - accuracy: 0.9062 - 60ms/epoch - 30ms/step\n",
      "Cummulative reward:  52\n",
      "\n",
      ">> Episode:  656 / 800\n",
      "2/2 - 0s - loss: 0.1524 - accuracy: 0.8438 - 58ms/epoch - 29ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  657 / 800\n",
      "2/2 - 0s - loss: 0.1272 - accuracy: 0.8906 - 58ms/epoch - 29ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  658 / 800\n",
      "2/2 - 0s - loss: 0.1205 - accuracy: 0.8594 - 60ms/epoch - 30ms/step\n",
      "Cummulative reward:  48\n",
      "\n",
      ">> Episode:  659 / 800\n",
      "2/2 - 0s - loss: 0.1212 - accuracy: 0.8750 - 61ms/epoch - 30ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  660 / 800\n",
      "2/2 - 0s - loss: 0.1418 - accuracy: 0.8438 - 75ms/epoch - 37ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  661 / 800\n",
      "2/2 - 0s - loss: 0.1057 - accuracy: 0.8906 - 59ms/epoch - 29ms/step\n",
      "Cummulative reward:  52\n",
      "\n",
      ">> Episode:  662 / 800\n",
      "2/2 - 0s - loss: 0.0806 - accuracy: 0.9219 - 60ms/epoch - 30ms/step\n",
      "Cummulative reward:  54\n",
      "\n",
      ">> Episode:  663 / 800\n",
      "2/2 - 0s - loss: 0.1456 - accuracy: 0.8594 - 58ms/epoch - 29ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  664 / 800\n",
      "2/2 - 0s - loss: 0.1417 - accuracy: 0.8594 - 56ms/epoch - 28ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  665 / 800\n",
      "2/2 - 0s - loss: 0.1513 - accuracy: 0.8438 - 58ms/epoch - 29ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  666 / 800\n",
      "2/2 - 0s - loss: 0.1981 - accuracy: 0.7812 - 59ms/epoch - 30ms/step\n",
      "Cummulative reward:  36\n",
      "\n",
      ">> Episode:  667 / 800\n",
      "2/2 - 0s - loss: 0.1505 - accuracy: 0.8438 - 75ms/epoch - 37ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  668 / 800\n",
      "2/2 - 0s - loss: 0.0542 - accuracy: 0.9531 - 69ms/epoch - 35ms/step\n",
      "Cummulative reward:  58\n",
      "\n",
      ">> Episode:  669 / 800\n",
      "2/2 - 0s - loss: 0.1484 - accuracy: 0.8281 - 63ms/epoch - 31ms/step\n",
      "Cummulative reward:  42\n",
      "\n",
      ">> Episode:  670 / 800\n",
      "2/2 - 0s - loss: 0.1243 - accuracy: 0.8750 - 61ms/epoch - 30ms/step\n",
      "Cummulative reward:  48\n",
      "\n",
      ">> Episode:  671 / 800\n",
      "2/2 - 0s - loss: 0.1090 - accuracy: 0.9531 - 60ms/epoch - 30ms/step\n",
      "Cummulative reward:  50\n",
      "\n",
      ">> Episode:  672 / 800\n",
      "2/2 - 0s - loss: 0.1384 - accuracy: 0.8594 - 61ms/epoch - 30ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  673 / 800\n",
      "2/2 - 0s - loss: 0.1205 - accuracy: 0.8594 - 60ms/epoch - 30ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  674 / 800\n",
      "2/2 - 0s - loss: 0.1066 - accuracy: 0.9062 - 58ms/epoch - 29ms/step\n",
      "Cummulative reward:  52\n",
      "\n",
      ">> Episode:  675 / 800\n",
      "2/2 - 0s - loss: 0.1237 - accuracy: 0.8906 - 61ms/epoch - 30ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  676 / 800\n",
      "2/2 - 0s - loss: 0.0902 - accuracy: 0.9062 - 61ms/epoch - 30ms/step\n",
      "Cummulative reward:  52\n",
      "\n",
      ">> Episode:  677 / 800\n",
      "2/2 - 0s - loss: 0.1068 - accuracy: 0.9062 - 65ms/epoch - 32ms/step\n",
      "Cummulative reward:  52\n",
      "\n",
      ">> Episode:  678 / 800\n",
      "2/2 - 0s - loss: 0.1335 - accuracy: 0.8750 - 61ms/epoch - 30ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  679 / 800\n",
      "2/2 - 0s - loss: 0.1396 - accuracy: 0.8594 - 59ms/epoch - 29ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  680 / 800\n",
      "2/2 - 0s - loss: 0.1037 - accuracy: 0.8906 - 59ms/epoch - 30ms/step\n",
      "Cummulative reward:  50\n",
      "\n",
      ">> Episode:  681 / 800\n",
      "2/2 - 0s - loss: 0.1630 - accuracy: 0.8438 - 59ms/epoch - 30ms/step\n",
      "Cummulative reward:  42\n",
      "\n",
      ">> Episode:  682 / 800\n",
      "2/2 - 0s - loss: 0.0804 - accuracy: 0.9062 - 61ms/epoch - 31ms/step\n",
      "Cummulative reward:  54\n",
      "\n",
      ">> Episode:  683 / 800\n",
      "2/2 - 0s - loss: 0.0852 - accuracy: 0.9219 - 62ms/epoch - 31ms/step\n",
      "Cummulative reward:  54\n",
      "\n",
      ">> Episode:  684 / 800\n",
      "2/2 - 0s - loss: 0.1090 - accuracy: 0.9062 - 60ms/epoch - 30ms/step\n",
      "Cummulative reward:  52\n",
      "\n",
      ">> Episode:  685 / 800\n",
      "2/2 - 0s - loss: 0.1637 - accuracy: 0.8125 - 134ms/epoch - 67ms/step\n",
      "Cummulative reward:  40\n",
      "\n",
      ">> Episode:  686 / 800\n",
      "2/2 - 0s - loss: 0.1784 - accuracy: 0.7969 - 76ms/epoch - 38ms/step\n",
      "Cummulative reward:  38\n",
      "\n",
      ">> Episode:  687 / 800\n",
      "2/2 - 0s - loss: 0.2146 - accuracy: 0.7812 - 61ms/epoch - 30ms/step\n",
      "Cummulative reward:  34\n",
      "\n",
      ">> Episode:  688 / 800\n",
      "2/2 - 0s - loss: 0.1038 - accuracy: 0.8750 - 61ms/epoch - 31ms/step\n",
      "Cummulative reward:  50\n",
      "\n",
      ">> Episode:  689 / 800\n",
      "2/2 - 0s - loss: 0.1325 - accuracy: 0.8750 - 72ms/epoch - 36ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  690 / 800\n",
      "2/2 - 0s - loss: 0.1419 - accuracy: 0.8594 - 61ms/epoch - 31ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  691 / 800\n",
      "2/2 - 0s - loss: 0.0703 - accuracy: 0.9375 - 58ms/epoch - 29ms/step\n",
      "Cummulative reward:  56\n",
      "\n",
      ">> Episode:  692 / 800\n",
      "2/2 - 0s - loss: 0.1197 - accuracy: 0.8906 - 60ms/epoch - 30ms/step\n",
      "Cummulative reward:  48\n",
      "\n",
      ">> Episode:  693 / 800\n",
      "2/2 - 0s - loss: 0.1510 - accuracy: 0.8438 - 61ms/epoch - 30ms/step\n",
      "Cummulative reward:  42\n",
      "\n",
      ">> Episode:  694 / 800\n",
      "2/2 - 0s - loss: 0.0919 - accuracy: 0.9062 - 60ms/epoch - 30ms/step\n",
      "Cummulative reward:  52\n",
      "\n",
      ">> Episode:  695 / 800\n",
      "2/2 - 0s - loss: 0.0919 - accuracy: 0.9062 - 59ms/epoch - 30ms/step\n",
      "Cummulative reward:  54\n",
      "\n",
      ">> Episode:  696 / 800\n",
      "2/2 - 0s - loss: 0.1163 - accuracy: 0.8906 - 61ms/epoch - 30ms/step\n",
      "Cummulative reward:  48\n",
      "\n",
      ">> Episode:  697 / 800\n",
      "2/2 - 0s - loss: 0.1580 - accuracy: 0.8125 - 60ms/epoch - 30ms/step\n",
      "Cummulative reward:  40\n",
      "\n",
      ">> Episode:  698 / 800\n",
      "2/2 - 0s - loss: 0.1578 - accuracy: 0.8281 - 63ms/epoch - 32ms/step\n",
      "Cummulative reward:  42\n",
      "\n",
      ">> Episode:  699 / 800\n",
      "2/2 - 0s - loss: 0.1448 - accuracy: 0.8594 - 59ms/epoch - 29ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  700 / 800\n",
      "2/2 - 0s - loss: 0.1503 - accuracy: 0.8438 - 59ms/epoch - 29ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  701 / 800\n",
      "2/2 - 0s - loss: 0.1234 - accuracy: 0.8594 - 60ms/epoch - 30ms/step\n",
      "Cummulative reward:  48\n",
      "\n",
      ">> Episode:  702 / 800\n",
      "2/2 - 0s - loss: 0.0972 - accuracy: 0.9062 - 59ms/epoch - 30ms/step\n",
      "Cummulative reward:  52\n",
      "\n",
      ">> Episode:  703 / 800\n",
      "2/2 - 0s - loss: 0.1819 - accuracy: 0.7656 - 60ms/epoch - 30ms/step\n",
      "Cummulative reward:  38\n",
      "\n",
      ">> Episode:  704 / 800\n",
      "2/2 - 0s - loss: 0.1163 - accuracy: 0.8906 - 60ms/epoch - 30ms/step\n",
      "Cummulative reward:  50\n",
      "\n",
      ">> Episode:  705 / 800\n",
      "2/2 - 0s - loss: 0.1285 - accuracy: 0.8750 - 61ms/epoch - 31ms/step\n",
      "Cummulative reward:  48\n",
      "\n",
      ">> Episode:  706 / 800\n",
      "2/2 - 0s - loss: 0.1057 - accuracy: 0.8906 - 61ms/epoch - 30ms/step\n",
      "Cummulative reward:  50\n",
      "\n",
      ">> Episode:  707 / 800\n",
      "2/2 - 0s - loss: 0.1396 - accuracy: 0.8281 - 60ms/epoch - 30ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  708 / 800\n",
      "2/2 - 0s - loss: 0.1049 - accuracy: 0.8906 - 60ms/epoch - 30ms/step\n",
      "Cummulative reward:  50\n",
      "\n",
      ">> Episode:  709 / 800\n",
      "2/2 - 0s - loss: 0.1003 - accuracy: 0.9062 - 59ms/epoch - 30ms/step\n",
      "Cummulative reward:  54\n",
      "\n",
      ">> Episode:  710 / 800\n",
      "2/2 - 0s - loss: 0.1684 - accuracy: 0.8594 - 61ms/epoch - 30ms/step\n",
      "Cummulative reward:  42\n",
      "\n",
      ">> Episode:  711 / 800\n",
      "2/2 - 0s - loss: 0.1530 - accuracy: 0.8438 - 58ms/epoch - 29ms/step\n",
      "Cummulative reward:  42\n",
      "\n",
      ">> Episode:  712 / 800\n",
      "2/2 - 0s - loss: 0.0694 - accuracy: 0.9219 - 59ms/epoch - 29ms/step\n",
      "Cummulative reward:  56\n",
      "\n",
      ">> Episode:  713 / 800\n",
      "2/2 - 0s - loss: 0.2018 - accuracy: 0.7656 - 60ms/epoch - 30ms/step\n",
      "Cummulative reward:  32\n",
      "\n",
      ">> Episode:  714 / 800\n",
      "2/2 - 0s - loss: 0.1077 - accuracy: 0.8750 - 61ms/epoch - 31ms/step\n",
      "Cummulative reward:  48\n",
      "\n",
      ">> Episode:  715 / 800\n",
      "2/2 - 0s - loss: 0.1216 - accuracy: 0.8750 - 63ms/epoch - 32ms/step\n",
      "Cummulative reward:  50\n",
      "\n",
      ">> Episode:  716 / 800\n",
      "2/2 - 0s - loss: 0.1346 - accuracy: 0.8750 - 64ms/epoch - 32ms/step\n",
      "Cummulative reward:  42\n",
      "\n",
      ">> Episode:  717 / 800\n",
      "2/2 - 0s - loss: 0.1651 - accuracy: 0.8125 - 64ms/epoch - 32ms/step\n",
      "Cummulative reward:  40\n",
      "\n",
      ">> Episode:  718 / 800\n",
      "2/2 - 0s - loss: 0.1292 - accuracy: 0.8906 - 65ms/epoch - 33ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  719 / 800\n",
      "2/2 - 0s - loss: 0.1826 - accuracy: 0.7812 - 61ms/epoch - 30ms/step\n",
      "Cummulative reward:  36\n",
      "\n",
      ">> Episode:  720 / 800\n",
      "2/2 - 0s - loss: 0.0972 - accuracy: 0.9062 - 63ms/epoch - 32ms/step\n",
      "Cummulative reward:  52\n",
      "\n",
      ">> Episode:  721 / 800\n",
      "2/2 - 0s - loss: 0.0851 - accuracy: 0.9375 - 65ms/epoch - 33ms/step\n",
      "Cummulative reward:  54\n",
      "\n",
      ">> Episode:  722 / 800\n",
      "2/2 - 0s - loss: 0.1114 - accuracy: 0.8906 - 64ms/epoch - 32ms/step\n",
      "Cummulative reward:  48\n",
      "\n",
      ">> Episode:  723 / 800\n",
      "2/2 - 0s - loss: 0.1914 - accuracy: 0.7812 - 65ms/epoch - 33ms/step\n",
      "Cummulative reward:  36\n",
      "\n",
      ">> Episode:  724 / 800\n",
      "2/2 - 0s - loss: 0.1297 - accuracy: 0.8594 - 63ms/epoch - 31ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  725 / 800\n",
      "2/2 - 0s - loss: 0.0938 - accuracy: 0.9062 - 63ms/epoch - 32ms/step\n",
      "Cummulative reward:  52\n",
      "\n",
      ">> Episode:  726 / 800\n",
      "2/2 - 0s - loss: 0.1418 - accuracy: 0.8750 - 63ms/epoch - 31ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  727 / 800\n",
      "2/2 - 0s - loss: 0.1320 - accuracy: 0.8594 - 66ms/epoch - 33ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  728 / 800\n",
      "2/2 - 0s - loss: 0.0905 - accuracy: 0.9375 - 63ms/epoch - 32ms/step\n",
      "Cummulative reward:  54\n",
      "\n",
      ">> Episode:  729 / 800\n",
      "2/2 - 0s - loss: 0.1658 - accuracy: 0.8125 - 73ms/epoch - 37ms/step\n",
      "Cummulative reward:  40\n",
      "\n",
      ">> Episode:  730 / 800\n",
      "2/2 - 0s - loss: 0.1533 - accuracy: 0.8438 - 84ms/epoch - 42ms/step\n",
      "Cummulative reward:  40\n",
      "\n",
      ">> Episode:  731 / 800\n",
      "2/2 - 0s - loss: 0.1365 - accuracy: 0.8594 - 61ms/epoch - 30ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  732 / 800\n",
      "2/2 - 0s - loss: 0.1502 - accuracy: 0.8125 - 62ms/epoch - 31ms/step\n",
      "Cummulative reward:  42\n",
      "\n",
      ">> Episode:  733 / 800\n",
      "2/2 - 0s - loss: 0.1703 - accuracy: 0.8125 - 62ms/epoch - 31ms/step\n",
      "Cummulative reward:  40\n",
      "\n",
      ">> Episode:  734 / 800\n",
      "2/2 - 0s - loss: 0.1250 - accuracy: 0.8594 - 63ms/epoch - 31ms/step\n",
      "Cummulative reward:  48\n",
      "\n",
      ">> Episode:  735 / 800\n",
      "2/2 - 0s - loss: 0.1189 - accuracy: 0.8906 - 64ms/epoch - 32ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  736 / 800\n",
      "2/2 - 0s - loss: 0.1428 - accuracy: 0.8438 - 66ms/epoch - 33ms/step\n",
      "Cummulative reward:  42\n",
      "\n",
      ">> Episode:  737 / 800\n",
      "2/2 - 0s - loss: 0.1069 - accuracy: 0.9062 - 66ms/epoch - 33ms/step\n",
      "Cummulative reward:  50\n",
      "\n",
      ">> Episode:  738 / 800\n",
      "2/2 - 0s - loss: 0.1056 - accuracy: 0.8750 - 64ms/epoch - 32ms/step\n",
      "Cummulative reward:  48\n",
      "\n",
      ">> Episode:  739 / 800\n",
      "2/2 - 0s - loss: 0.1701 - accuracy: 0.8125 - 64ms/epoch - 32ms/step\n",
      "Cummulative reward:  38\n",
      "\n",
      ">> Episode:  740 / 800\n",
      "2/2 - 0s - loss: 0.1950 - accuracy: 0.8125 - 63ms/epoch - 31ms/step\n",
      "Cummulative reward:  34\n",
      "\n",
      ">> Episode:  741 / 800\n",
      "2/2 - 0s - loss: 0.0936 - accuracy: 0.9219 - 66ms/epoch - 33ms/step\n",
      "Cummulative reward:  54\n",
      "\n",
      ">> Episode:  742 / 800\n",
      "2/2 - 0s - loss: 0.0898 - accuracy: 0.9375 - 63ms/epoch - 32ms/step\n",
      "Cummulative reward:  50\n",
      "\n",
      ">> Episode:  743 / 800\n",
      "2/2 - 0s - loss: 0.1567 - accuracy: 0.8281 - 61ms/epoch - 31ms/step\n",
      "Cummulative reward:  40\n",
      "\n",
      ">> Episode:  744 / 800\n",
      "2/2 - 0s - loss: 0.1911 - accuracy: 0.7969 - 68ms/epoch - 34ms/step\n",
      "Cummulative reward:  34\n",
      "\n",
      ">> Episode:  745 / 800\n",
      "2/2 - 0s - loss: 0.0988 - accuracy: 0.9062 - 106ms/epoch - 53ms/step\n",
      "Cummulative reward:  50\n",
      "\n",
      ">> Episode:  746 / 800\n",
      "2/2 - 0s - loss: 0.1459 - accuracy: 0.8594 - 70ms/epoch - 35ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  747 / 800\n",
      "2/2 - 0s - loss: 0.1697 - accuracy: 0.8281 - 83ms/epoch - 42ms/step\n",
      "Cummulative reward:  36\n",
      "\n",
      ">> Episode:  748 / 800\n",
      "2/2 - 0s - loss: 0.1318 - accuracy: 0.8438 - 63ms/epoch - 31ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  749 / 800\n",
      "2/2 - 0s - loss: 0.1540 - accuracy: 0.8281 - 69ms/epoch - 34ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  750 / 800\n",
      "2/2 - 0s - loss: 0.1840 - accuracy: 0.7812 - 73ms/epoch - 37ms/step\n",
      "Cummulative reward:  38\n",
      "\n",
      ">> Episode:  751 / 800\n",
      "2/2 - 0s - loss: 0.1301 - accuracy: 0.8750 - 73ms/epoch - 36ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  752 / 800\n",
      "2/2 - 0s - loss: 0.1599 - accuracy: 0.8281 - 71ms/epoch - 36ms/step\n",
      "Cummulative reward:  42\n",
      "\n",
      ">> Episode:  753 / 800\n",
      "2/2 - 0s - loss: 0.1067 - accuracy: 0.8906 - 71ms/epoch - 35ms/step\n",
      "Cummulative reward:  50\n",
      "\n",
      ">> Episode:  754 / 800\n",
      "2/2 - 0s - loss: 0.1323 - accuracy: 0.8594 - 72ms/epoch - 36ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  755 / 800\n",
      "2/2 - 0s - loss: 0.1203 - accuracy: 0.8750 - 75ms/epoch - 38ms/step\n",
      "Cummulative reward:  48\n",
      "\n",
      ">> Episode:  756 / 800\n",
      "2/2 - 0s - loss: 0.1307 - accuracy: 0.8594 - 72ms/epoch - 36ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  757 / 800\n",
      "2/2 - 0s - loss: 0.1452 - accuracy: 0.8438 - 79ms/epoch - 40ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  758 / 800\n",
      "2/2 - 0s - loss: 0.0772 - accuracy: 0.9219 - 71ms/epoch - 36ms/step\n",
      "Cummulative reward:  54\n",
      "\n",
      ">> Episode:  759 / 800\n",
      "2/2 - 0s - loss: 0.1476 - accuracy: 0.8281 - 71ms/epoch - 35ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  760 / 800\n",
      "2/2 - 0s - loss: 0.1309 - accuracy: 0.8594 - 71ms/epoch - 35ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  761 / 800\n",
      "2/2 - 0s - loss: 0.1562 - accuracy: 0.8281 - 69ms/epoch - 34ms/step\n",
      "Cummulative reward:  42\n",
      "\n",
      ">> Episode:  762 / 800\n",
      "2/2 - 0s - loss: 0.1611 - accuracy: 0.8125 - 64ms/epoch - 32ms/step\n",
      "Cummulative reward:  40\n",
      "\n",
      ">> Episode:  763 / 800\n",
      "2/2 - 0s - loss: 0.0776 - accuracy: 0.9531 - 112ms/epoch - 56ms/step\n",
      "Cummulative reward:  54\n",
      "\n",
      ">> Episode:  764 / 800\n",
      "2/2 - 0s - loss: 0.0718 - accuracy: 0.9219 - 67ms/epoch - 33ms/step\n",
      "Cummulative reward:  56\n",
      "\n",
      ">> Episode:  765 / 800\n",
      "2/2 - 0s - loss: 0.1811 - accuracy: 0.8281 - 65ms/epoch - 32ms/step\n",
      "Cummulative reward:  38\n",
      "\n",
      ">> Episode:  766 / 800\n",
      "2/2 - 0s - loss: 0.1363 - accuracy: 0.8750 - 66ms/epoch - 33ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  767 / 800\n",
      "2/2 - 0s - loss: 0.1254 - accuracy: 0.8750 - 105ms/epoch - 53ms/step\n",
      "Cummulative reward:  48\n",
      "\n",
      ">> Episode:  768 / 800\n",
      "2/2 - 0s - loss: 0.0931 - accuracy: 0.8906 - 128ms/epoch - 64ms/step\n",
      "Cummulative reward:  52\n",
      "\n",
      ">> Episode:  769 / 800\n",
      "2/2 - 0s - loss: 0.1070 - accuracy: 0.8750 - 104ms/epoch - 52ms/step\n",
      "Cummulative reward:  48\n",
      "\n",
      ">> Episode:  770 / 800\n",
      "2/2 - 0s - loss: 0.1132 - accuracy: 0.8906 - 96ms/epoch - 48ms/step\n",
      "Cummulative reward:  50\n",
      "\n",
      ">> Episode:  771 / 800\n",
      "2/2 - 0s - loss: 0.1000 - accuracy: 0.8906 - 97ms/epoch - 48ms/step\n",
      "Cummulative reward:  48\n",
      "\n",
      ">> Episode:  772 / 800\n",
      "2/2 - 0s - loss: 0.0824 - accuracy: 0.9219 - 77ms/epoch - 39ms/step\n",
      "Cummulative reward:  54\n",
      "\n",
      ">> Episode:  773 / 800\n",
      "2/2 - 0s - loss: 0.1333 - accuracy: 0.8750 - 74ms/epoch - 37ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  774 / 800\n",
      "2/2 - 0s - loss: 0.1254 - accuracy: 0.8906 - 110ms/epoch - 55ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  775 / 800\n",
      "2/2 - 0s - loss: 0.1129 - accuracy: 0.8906 - 74ms/epoch - 37ms/step\n",
      "Cummulative reward:  48\n",
      "\n",
      ">> Episode:  776 / 800\n",
      "2/2 - 0s - loss: 0.0960 - accuracy: 0.8750 - 80ms/epoch - 40ms/step\n",
      "Cummulative reward:  52\n",
      "\n",
      ">> Episode:  777 / 800\n",
      "2/2 - 0s - loss: 0.1237 - accuracy: 0.8750 - 69ms/epoch - 35ms/step\n",
      "Cummulative reward:  48\n",
      "\n",
      ">> Episode:  778 / 800\n",
      "2/2 - 0s - loss: 0.1126 - accuracy: 0.9062 - 88ms/epoch - 44ms/step\n",
      "Cummulative reward:  50\n",
      "\n",
      ">> Episode:  779 / 800\n",
      "2/2 - 0s - loss: 0.1495 - accuracy: 0.8594 - 70ms/epoch - 35ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  780 / 800\n",
      "2/2 - 0s - loss: 0.1668 - accuracy: 0.8438 - 72ms/epoch - 36ms/step\n",
      "Cummulative reward:  42\n",
      "\n",
      ">> Episode:  781 / 800\n",
      "2/2 - 0s - loss: 0.0998 - accuracy: 0.9062 - 76ms/epoch - 38ms/step\n",
      "Cummulative reward:  50\n",
      "\n",
      ">> Episode:  782 / 800\n",
      "2/2 - 0s - loss: 0.0777 - accuracy: 0.9219 - 71ms/epoch - 35ms/step\n",
      "Cummulative reward:  52\n",
      "\n",
      ">> Episode:  783 / 800\n",
      "2/2 - 0s - loss: 0.1891 - accuracy: 0.8125 - 77ms/epoch - 39ms/step\n",
      "Cummulative reward:  38\n",
      "\n",
      ">> Episode:  784 / 800\n",
      "2/2 - 0s - loss: 0.1268 - accuracy: 0.8594 - 73ms/epoch - 36ms/step\n",
      "Cummulative reward:  46\n",
      "\n",
      ">> Episode:  785 / 800\n",
      "2/2 - 0s - loss: 0.1836 - accuracy: 0.7969 - 71ms/epoch - 36ms/step\n",
      "Cummulative reward:  36\n",
      "\n",
      ">> Episode:  786 / 800\n",
      "2/2 - 0s - loss: 0.1470 - accuracy: 0.8281 - 68ms/epoch - 34ms/step\n",
      "Cummulative reward:  42\n",
      "\n",
      ">> Episode:  787 / 800\n",
      "2/2 - 0s - loss: 0.1327 - accuracy: 0.8594 - 72ms/epoch - 36ms/step\n",
      "Cummulative reward:  48\n",
      "\n",
      ">> Episode:  788 / 800\n",
      "2/2 - 0s - loss: 0.1508 - accuracy: 0.8125 - 71ms/epoch - 35ms/step\n",
      "Cummulative reward:  40\n",
      "\n",
      ">> Episode:  789 / 800\n",
      "2/2 - 0s - loss: 0.1170 - accuracy: 0.9062 - 73ms/epoch - 37ms/step\n",
      "Cummulative reward:  50\n",
      "\n",
      ">> Episode:  790 / 800\n",
      "2/2 - 0s - loss: 0.1188 - accuracy: 0.8906 - 70ms/epoch - 35ms/step\n",
      "Cummulative reward:  50\n",
      "\n",
      ">> Episode:  791 / 800\n",
      "2/2 - 0s - loss: 0.1340 - accuracy: 0.8594 - 72ms/epoch - 36ms/step\n",
      "Cummulative reward:  44\n",
      "\n",
      ">> Episode:  792 / 800\n",
      "2/2 - 0s - loss: 0.0962 - accuracy: 0.9219 - 70ms/epoch - 35ms/step\n",
      "Cummulative reward:  52\n",
      "\n",
      ">> Episode:  793 / 800\n",
      "2/2 - 0s - loss: 0.1463 - accuracy: 0.8281 - 74ms/epoch - 37ms/step\n",
      "Cummulative reward:  42\n",
      "\n",
      ">> Episode:  794 / 800\n",
      "2/2 - 0s - loss: 0.0825 - accuracy: 0.9219 - 73ms/epoch - 36ms/step\n",
      "Cummulative reward:  54\n",
      "\n",
      ">> Episode:  795 / 800\n",
      "2/2 - 0s - loss: 0.0843 - accuracy: 0.9219 - 72ms/epoch - 36ms/step\n",
      "Cummulative reward:  54\n",
      "\n",
      ">> Episode:  796 / 800\n",
      "2/2 - 0s - loss: 0.1171 - accuracy: 0.8750 - 75ms/epoch - 37ms/step\n",
      "Cummulative reward:  48\n",
      "\n",
      ">> Episode:  797 / 800\n",
      "2/2 - 0s - loss: 0.0889 - accuracy: 0.9062 - 73ms/epoch - 36ms/step\n",
      "Cummulative reward:  54\n",
      "\n",
      ">> Episode:  798 / 800\n",
      "2/2 - 0s - loss: 0.1111 - accuracy: 0.8906 - 73ms/epoch - 37ms/step\n",
      "Cummulative reward:  48\n",
      "\n",
      ">> Episode:  799 / 800\n",
      "2/2 - 0s - loss: 0.1894 - accuracy: 0.7969 - 71ms/epoch - 35ms/step\n",
      "Cummulative reward:  38\n",
      "\n",
      ">> Episode:  800 / 800\n",
      "2/2 - 0s - loss: 0.1333 - accuracy: 0.8438 - 71ms/epoch - 36ms/step\n",
      "Cummulative reward:  44\n"
     ]
    }
   ],
   "source": [
    "# Initialization:\n",
    "\n",
    "# environment\n",
    "trainX, trainy, testX, testy = load_dataset() # load dataset (x = state, y = action)\n",
    "\n",
    "env = PowerPlantEnv(dataset=(trainX, trainy))\n",
    "action_space = [0,1,2] # action space: {0: healthy, 1: OR fault, 2: IR fault}\n",
    "\n",
    "E = 800 # training episode number\n",
    "M = 300 # experience pool capacity\n",
    "R = 64 # replay size\n",
    "T = 64 # game rounds in one episode\n",
    "C = 10 # copy period: training steps to update periodicity of target network\n",
    "\n",
    "discount_factor = 0.01 # gamma\n",
    "learning_rate = 0.001 # alpha\n",
    "\n",
    "# epsilon-greedy:\n",
    "# tradeoff between exploration and exploitation\n",
    "epsilon_0 = 0.4  # exploration probability at start\n",
    "epsilon_min = 0.01  # minimum exploration probability\n",
    "epsilon_decay = 0.3  # exponential decay rate for exploration prob\n",
    "\n",
    "cum_reward_episode = []\n",
    "acc_episode = []\n",
    "loss_episode = []\n",
    "\n",
    "ddqn_agent = DDQNAgent(learning_rate=learning_rate, discount_factor=discount_factor, \\\n",
    "                                action_space=action_space, \\\n",
    "                                trainX=trainX, trainy=trainy, batch_size=R, \\\n",
    "                                epsilon_0=epsilon_0, epsilon_decay=epsilon_decay, \\\n",
    "                                epsilon_min=epsilon_min, mem_size=M, replace_target=C)\n",
    "\n",
    "for e in range(1,E+1): # training episode\n",
    "    env = PowerPlantEnv(dataset=(trainX, trainy)) # reset environment\n",
    "    ddqn_agent.reset_pool(M) # reset experience pool\n",
    "    ddqn_agent.set_episode_count(e) # set the counter with the number of episodes\n",
    "    cum_reward = 0\n",
    "    print(\"\\n>> Episode: \",e,\"/\",E)\n",
    "    observation = env._next_obs()\n",
    "    ddqn_agent.update_epsilon()\n",
    "    for t in range(1,T+1): # game round\n",
    "        action = ddqn_agent.choose_action(observation)\n",
    "        observation_, reward, done, info = env.step(action)\n",
    "        done = (t==T)\n",
    "        cum_reward += reward\n",
    "        exp = Experience(observation, action, reward, observation_, int(done))\n",
    "        ddqn_agent.add_experience(exp)\n",
    "        observation = observation_\n",
    "        acc, loss = ddqn_agent.learn()\n",
    "    cum_reward_episode.append(cum_reward)\n",
    "    acc_episode.append(acc)\n",
    "    loss_episode.append(loss)\n",
    "    print(\"Cummulative reward: \",cum_reward)\n",
    "\n",
    "# save model\n",
    "ddqn_model = ddqn_agent.q_policy\n",
    "models_dir = 'models/'\n",
    "existing_models = [filename for filename in os.listdir(models_dir) if filename.startswith('ddqn_model')]\n",
    "num_model = len(existing_models)+1\n",
    "filename = f'models/ddqn_model_{num_model}.h5'\n",
    "ddqn_model.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# E = 800 # training episode number ==> aumentar epochs\n",
    "# M = 300 # experience pool capacity\n",
    "# R = 64 # replay size\n",
    "# T = 64 # game rounds in one episode\n",
    "# C = 10 # copy period: training steps to update periodicity of target network\n",
    "# discount_factor = 0.01 # gamma\n",
    "# learning_rate = 0.001 # alpha\n",
    "# # epsilon-greedy:\n",
    "# # tradeoff between exploration and exploitation\n",
    "# epsilon_0 = 0.4  # exploration probability at start\n",
    "# epsilon_min = 0.01  # minimum exploration probability\n",
    "# epsilon_decay = 0.3  # exponential decay rate for exploration prob\n",
    "# Modelo con 2 capas de Conv1D\n",
    "# con datos normalizados!\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "axs[0].plot(acc_episode)\n",
    "axs[0].set(xlabel='Accuracy')\n",
    "\n",
    "axs[1].plot(loss_episode)\n",
    "axs[1].set(xlabel='Loss')\n",
    "\n",
    "axs[2].plot(cum_reward_episode)\n",
    "axs[2].set(xlabel='Reward')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "330/330 [==============================] - 5s 15ms/step\n",
      "Test accuracy:  0.8537695590327169\n"
     ]
    }
   ],
   "source": [
    "pred_test = ddqn_model.predict(testX)\n",
    "\n",
    "test_acc = accuracy_score(np.argmax(testy,axis=1), np.argmax(pred_test,axis=1))\n",
    "print('Test accuracy: ',test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy     0.9129    0.8440    0.8771      3552\n",
      "    OR fault     0.9260    0.8061    0.8619      3600\n",
      "    IR fault     0.7519    0.9145    0.8253      3393\n",
      "\n",
      "    accuracy                         0.8538     10545\n",
      "   macro avg     0.8636    0.8549    0.8548     10545\n",
      "weighted avg     0.8656    0.8538    0.8552     10545\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(np.argmax(testy,axis=1), np.argmax(pred_test,axis=1), target_names=['Healthy', 'OR fault', 'IR fault'],digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "colorscale": [
          [
           0,
           "rgb(0, 147, 146)"
          ],
          [
           0.16666666666666666,
           "rgb(114, 170, 161)"
          ],
          [
           0.3333333333333333,
           "rgb(177, 199, 179)"
          ],
          [
           0.5,
           "rgb(241, 234, 200)"
          ],
          [
           0.6666666666666666,
           "rgb(229, 185, 173)"
          ],
          [
           0.8333333333333334,
           "rgb(217, 137, 148)"
          ],
          [
           1,
           "rgb(208, 88, 126)"
          ]
         ],
         "reversescale": false,
         "showscale": false,
         "type": "heatmap",
         "x": [
          "Healthy",
          "OR fault",
          "IR fault"
         ],
         "y": [
          "IR fault",
          "OR fault",
          "Healthy"
         ],
         "z": [
          [
           156,
           134,
           3103
          ],
          [
           130,
           2902,
           568
          ],
          [
           2998,
           98,
           456
          ]
         ]
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "156",
          "x": "Healthy",
          "xref": "x",
          "y": "IR fault",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "134",
          "x": "OR fault",
          "xref": "x",
          "y": "IR fault",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "3103",
          "x": "IR fault",
          "xref": "x",
          "y": "IR fault",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "130",
          "x": "Healthy",
          "xref": "x",
          "y": "OR fault",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "2902",
          "x": "OR fault",
          "xref": "x",
          "y": "OR fault",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "568",
          "x": "IR fault",
          "xref": "x",
          "y": "OR fault",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "2998",
          "x": "Healthy",
          "xref": "x",
          "y": "Healthy",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "98",
          "x": "OR fault",
          "xref": "x",
          "y": "Healthy",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "456",
          "x": "IR fault",
          "xref": "x",
          "y": "Healthy",
          "yref": "y"
         }
        ],
        "height": 300,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Testing"
        },
        "width": 600,
        "xaxis": {
         "dtick": 1,
         "gridcolor": "rgb(0, 0, 0)",
         "side": "top",
         "ticks": "",
         "title": {
          "text": "Predicted Label"
         }
        },
        "yaxis": {
         "dtick": 1,
         "ticks": "",
         "ticksuffix": "  ",
         "title": {
          "text": "True Label"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# testing\n",
    "# Construimos una visualización para la matriz de confusión\n",
    "z_test = confusion_matrix(np.argmax(testy,axis=1), np.argmax(pred_test,axis=1))\n",
    "# Reformateo la matriz para que me quede mejor el gráfico\n",
    "z_test[[0,2],:] = z_test[[2,0],:]\n",
    "x = ['Healthy', 'OR fault', 'IR fault']\n",
    "y = ['IR fault', 'OR fault', 'Healthy']\n",
    "z_text = [[str(y) for y in x] for x in z_test]\n",
    "heatmap = ff.create_annotated_heatmap(z_test, x=x, y=y, annotation_text=z_text, colorscale='tealrose')\n",
    "heatmap.update_layout(title_text='Testing',height=300,width=600,\n",
    "                      xaxis_title=\"Predicted Label\",yaxis_title=\"True Label\")\n",
    "heatmap.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "55923a6ed19f62c923f4f9446379b87364bb44c28ea18797870eef05a25fc661"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
