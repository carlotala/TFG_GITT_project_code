{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and preprocess data\n",
    "This code reads the data files, performs some transformations to prepare the data and does the train, test and validation split and saves the numpy arrays to use for the construction, training and testing of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.io as sio\n",
    "from scipy.fft import fft, fftfreq\n",
    "from keras.utils import to_categorical\n",
    "import os\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a single file as a numpy array changing to frequency domain\n",
    "def load_file(filepath, filename):\n",
    "\tdata = sio.loadmat(filepath)\n",
    "\t\n",
    "\t# vibration data\n",
    "\tvib_data = data[filename]['Y'][0][0][0][6][2].transpose()\n",
    "\tvib_data = vib_data.reshape(vib_data.shape[0],)\n",
    "\n",
    "\t# frequency domain and splitting into samples of size 1024 (512 in freq)\n",
    "\tn_loop = round(vib_data.shape[0]/1024)\n",
    "\tvib_freq = np.zeros([n_loop,512])\n",
    "\tfor i in range(n_loop):\n",
    "\t\tvib_data_1024 = vib_data[1024*i:1024*(1+i)]\n",
    "\t\tvib_freq[i] = np.abs(fft(vib_data_1024))[0:1024//2]\n",
    "\n",
    "\treturn vib_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a dataset group\n",
    "def load_dataset_group(prefix='',group='', setting=''):\n",
    "\tfilepath = prefix + group + '/' + setting\n",
    "\n",
    "\t# load all 20 files as a single array\n",
    "\t# X will have 20*N rows and 512 columns\n",
    "\t# where N is the number of rows of each file when splitting into samples\n",
    "\tX = np.zeros([1,512])\n",
    "\n",
    "\t# Instead of reading all 20 measurements, only 2 to reduce dataset length\n",
    "\t# and 4 for the healthy to have balanced dataset\n",
    "\tif group=='K001' or group=='K002' or group=='K003' or group=='K004' or group=='K005' or group=='K006': # healthy\n",
    "\t\tmeasurements = 4\n",
    "\telse:\n",
    "\t\tmeasurements = 2\n",
    "\t\t\n",
    "\tfor i in range(1,measurements+1):\n",
    "\t\ttry:\n",
    "\t\t\tpath = filepath+'_'+group+'_'+str(i)+'.mat'\n",
    "\t\t\tfilename = setting+'_'+group+'_'+str(i)\n",
    "\t\t\tif i == 1:\n",
    "\t\t\t\tX = load_file(path,filename)\n",
    "\t\t\telse:\n",
    "\t\t\t\tX = np.concatenate([X,load_file(path,filename)],axis=0)\n",
    "\t\texcept Exception as e: # if the loading the file fails, load another one\n",
    "\t\t\tpath = filepath+'_'+group+'_'+str(i+10)+'.mat'\n",
    "\t\t\tfilename = setting+'_'+group+'_'+str(i+10)\n",
    "\t\t\tX = np.concatenate([X,load_file(path,filename)],axis=0)\n",
    "\t\n",
    "\t# load class output\n",
    "\tif group=='K001' or group=='K002' or group=='K003' or group=='K004' or group=='K005' or group=='K006': # healthy\n",
    "\t\ty = np.ones(X.shape[0])\n",
    "\telif group=='KA04' or group=='KA15' or group=='KA16' or group=='KA22' or group=='KA30':# real OR damage\n",
    "\t\ty = np.ones(X.shape[0])*2\n",
    "\telif group=='KI04' or group=='KI14' or group=='KI16' or group=='KI17' or group=='KI18' or group=='KI21':# real IR damage\n",
    "\t\ty = np.ones(X.shape[0])*3\n",
    "\telif group=='KA01' or group=='KA03' or group=='KA05' or group=='KA06' or group=='KA07' or group=='KA08' or group=='KA09':# artificial OR damage\n",
    "\t\ty = np.ones(X.shape[0])*2\n",
    "\telif group=='KI01' or group=='KI03' or group=='KI05' or group=='KI07' or group=='KI08':# artificial IR damage\n",
    "\t\ty = np.ones(X.shape[0])*3\n",
    "\telse:\n",
    "\t\ty = np.zeros(X.shape[0])\n",
    "\treturn X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_directory_names(path):\n",
    "    # get a list of all items (files and directories) in the folder\n",
    "    items = os.listdir(path)\n",
    "\n",
    "    # initialize an empty list for folder names\n",
    "    folder_names = []\n",
    "\n",
    "    # loop over each item in the folder\n",
    "    for item in items:\n",
    "        # get the full path to the item\n",
    "        item_path = os.path.join(path, item)\n",
    "        \n",
    "        # check if the item is a directory\n",
    "        if os.path.isdir(item_path):\n",
    "            # append the folder name to the list of folder names\n",
    "            folder_names.append(item)\n",
    "\n",
    "    return folder_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset, returns train and test X and y elements\n",
    "def load_dataset(prefix=''):\n",
    "\t\"\"\"\n",
    "\tOutput:\n",
    "\t- trainX, testX, valX: numpy arrays of shape (n_samples, 512, 2)\n",
    "\t\t512 frequency data points for each sample and the rotational speed for each sample\n",
    "\t- trainy, testy, valy: numpy arrays of shape (n_samples, 3)\n",
    "\t\tone hot endcoding of y for the 3 classes (healthy, inside ring damage, outside ring damage)\n",
    "\t\"\"\"\n",
    "\n",
    "\t# load all data\n",
    "\tfolder_names = get_directory_names('data/raw')\n",
    "\tX_list = []\n",
    "\ty_list = []\n",
    "\n",
    "\tsettings_speed={'N15_M07_F10':1500,\n",
    "\t\t\t\t\t'N09_M07_F10':900,\n",
    "\t\t\t\t\t'N15_M01_F10':1500,\n",
    "\t\t\t\t\t'N15_M07_F04':1500}\n",
    "\t\n",
    "\tfor setting in settings_speed.keys():\n",
    "\t\tfor group in folder_names:\n",
    "\t\t\tX_group, y_group = load_dataset_group(prefix+'data/raw/', group, setting)\n",
    "\t\t\tX_group = X_group.reshape(X_group.shape[0],X_group.shape[1],1)\n",
    "\n",
    "\t\t\t# create an array of shape (n_samples, 512, 1) containing the same speed value\n",
    "\t\t\tspeed = np.full((X_group.shape[0], X_group.shape[1], 1), settings_speed.get(setting))\n",
    "\n",
    "\t\t\t# concatenate X and speed along the last axis\n",
    "\t\t\tX_group_speed = np.concatenate([X_group, speed], axis=2)\n",
    "\n",
    "\t\t\tX_list.append(X_group_speed)\n",
    "\t\t\ty_list.append(y_group)\n",
    "\t\t\t\n",
    "\n",
    "\tX = np.concatenate(X_list, axis=0)\n",
    "\ty = np.concatenate(y_list, axis=0)\n",
    "\n",
    "\t# train/test/validation split\n",
    "\ttrainX, testValX, trainy, testValy = train_test_split(X, y.ravel(), test_size = 0.3, random_state = 42)\n",
    "\ttestX, valX, testy, valy = train_test_split(testValX, testValy, test_size = 0.5, random_state = 42)\n",
    "\t\n",
    "\t# zero-offset class values\n",
    "\ttrainy = trainy - 1\n",
    "\ttesty = testy - 1\n",
    "\tvaly = valy - 1\n",
    "\t# one hot encode y\n",
    "\ttrainy = to_categorical(trainy)\n",
    "\ttesty = to_categorical(testy)\n",
    "\tvaly = to_categorical(valy)\n",
    "\t\n",
    "\tprint(\"train: \",trainX.shape, trainy.shape, \"\\ntest: \", testX.shape, testy.shape, \"\\nval: \", valX.shape, valy.shape)\n",
    "\treturn trainX, trainy, testX, testy, valX, valy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  (49209, 512, 2) (49209, 3) \n",
      "test:  (10545, 512, 2) (10545, 3) \n",
      "val:  (10545, 512, 2) (10545, 3)\n"
     ]
    }
   ],
   "source": [
    "trainX, trainy, testX, testy, valX, valy = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    16899\n",
       "0    16885\n",
       "2    15425\n",
       "dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that data is balanced\n",
    "pd.DataFrame(np.argmax(trainy,axis=1)).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "with open('data/processed/trainX.npy', 'wb') as f:\n",
    "    np.save(f, trainX)\n",
    "with open('data/processed/trainy.npy', 'wb') as f:\n",
    "    np.save(f, trainy)\n",
    "with open('data/processed/testX.npy', 'wb') as f:\n",
    "    np.save(f, testX)\n",
    "with open('data/processed/testy.npy', 'wb') as f:\n",
    "    np.save(f, testy)\n",
    "with open('data/processed/valX.npy', 'wb') as f:\n",
    "    np.save(f, valX)\n",
    "with open('data/processed/valy.npy', 'wb') as f:\n",
    "    np.save(f, valy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize some data in time and frequency graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_X_time(path,data,setting):\n",
    "    X = sio.loadmat(path+data+'/'+setting+'_'+data+'_1')[setting+'_'+data+'_1']['Y'][0][0][0][6][2].transpose()\n",
    "    X = X.reshape(X.shape[0],)\n",
    "    return X\n",
    "\n",
    "X_k001 = load_X_time('data/raw/', 'K001', 'N15_M07_F10') # healthy\n",
    "X_k002 = load_X_time('data/raw/', 'K002', 'N15_M07_F10') # healthy\n",
    "\n",
    "X_ka01 = load_X_time('data/raw/', 'KA01', 'N15_M07_F10') # artificial OR damage\n",
    "X_ka04 = load_X_time('data/raw/', 'KA04', 'N15_M07_F10') # real OR damage\n",
    "\n",
    "X_ki01 = load_X_time('data/raw/', 'KI01', 'N15_M07_F10') # artificial IR damage\n",
    "X_ki04 = load_X_time('data/raw/', 'KI04', 'N15_M07_F10') # real IR damage\n",
    "\n",
    "# Crear subplots:\n",
    "fig = make_subplots(rows=6, cols=2)\n",
    "\n",
    "# Tiempo\n",
    "fig.add_trace(\n",
    "    go.Scatter(x= np.linspace(0,4,X_k001.shape[0]), y=X_k001, marker_color='green', showlegend=False),\n",
    "    row=1, col=1\n",
    ")\n",
    "fig.update_yaxes(title_text=\"Healthy\", row=1, col=1)\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x= np.linspace(0,4,X_k002.shape[0]), y=X_k002, marker_color='green', showlegend=False),\n",
    "    row=2, col=1\n",
    ")\n",
    "fig.update_yaxes(title_text=\"Healthy\", row=2, col=1)\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x= np.linspace(0,4,X_ka01.shape[0]), y=X_ka01, marker_color='firebrick', showlegend=False),\n",
    "    row=3, col=1\n",
    ")\n",
    "fig.update_yaxes(title_text=\"OR artificial\", row=3, col=1)\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x= np.linspace(0,4,X_ka04.shape[0]), y=X_ka04, marker_color='firebrick', showlegend=False),\n",
    "    row=4, col=1\n",
    ")\n",
    "fig.update_yaxes(title_text=\"OR real\", row=4, col=1)\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x= np.linspace(0,4,X_ki01.shape[0]), y=X_ki01, marker_color='steelblue', showlegend=False),\n",
    "    row=5, col=1\n",
    ")\n",
    "fig.update_yaxes(title_text=\"IR artificial\", row=5, col=1)\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x= np.linspace(0,4,X_ki04.shape[0]), y=X_ki04, marker_color='steelblue', showlegend=False),\n",
    "    row=6, col=1\n",
    ")\n",
    "fig.update_yaxes(title_text=\"IR real\", row=6, col=1)\n",
    "\n",
    "fig.update_xaxes(title_text=\"Seconds (s)\", row=6, col=1)\n",
    "\n",
    "# Frecuencia\n",
    "freqk001 = X_k001.shape[0]/4\n",
    "xfk001 = fftfreq(X_k001.shape[0],1/freqk001)\n",
    "fig.add_trace(\n",
    "    go.Scatter(x= xfk001[:X_k001.shape[0]//2], y=np.abs(fft(X_k001))[0:X_k001.shape[0]//2], marker_color='green', showlegend=False),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "freqk002 = X_k002.shape[0]/4\n",
    "xfk002 = fftfreq(X_k002.shape[0],1/freqk002)\n",
    "fig.add_trace(\n",
    "    go.Scatter(x= xfk002[:X_k002.shape[0]//2], y=np.abs(fft(X_k002))[0:X_k002.shape[0]//2], marker_color='green', showlegend=False),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "freqka01 = X_ka01.shape[0]/4\n",
    "xfka01 = fftfreq(X_ka01.shape[0],1/freqka01)\n",
    "fig.add_trace(\n",
    "    go.Scatter(x= xfka01[:X_ka01.shape[0]//2], y=np.abs(fft(X_ka01))[0:X_ka01.shape[0]//2], marker_color='firebrick', showlegend=False),\n",
    "    row=3, col=2\n",
    ")\n",
    "\n",
    "freqka04 = X_ka04.shape[0]/4\n",
    "xfka04 = fftfreq(X_ka04.shape[0],1/freqka04)\n",
    "fig.add_trace(\n",
    "    go.Scatter(x= xfka04[:X_ka04.shape[0]//2], y=np.abs(fft(X_ka04))[0:X_ka04.shape[0]//2], marker_color='firebrick', showlegend=False),\n",
    "    row=4, col=2\n",
    ")\n",
    "\n",
    "freqki01 = X_ki01.shape[0]/4\n",
    "xfki01 = fftfreq(X_ki01.shape[0],1/freqki01)\n",
    "fig.add_trace(\n",
    "    go.Scatter(x= xfki01[:X_ki01.shape[0]//2], y=np.abs(fft(X_ki01))[0:X_ki01.shape[0]//2], marker_color='steelblue', showlegend=False),\n",
    "    row=5, col=2\n",
    ")\n",
    "\n",
    "freqki04 = X_ki04.shape[0]/4\n",
    "xfki04 = fftfreq(X_ki04.shape[0],1/freqki04)\n",
    "fig.add_trace(\n",
    "    go.Scatter(x= xfki04[:X_ki04.shape[0]//2], y=np.abs(fft(X_ki04))[0:X_ki04.shape[0]//2], marker_color='steelblue', showlegend=False),\n",
    "    row=6, col=2\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title_text=\"Frequency (Hz)\", row=6, col=2)\n",
    "\n",
    "fig.update_layout(height=1000, width=800)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "55923a6ed19f62c923f4f9446379b87364bb44c28ea18797870eef05a25fc661"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
